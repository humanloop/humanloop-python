# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from ..core.request_options import RequestOptions
from ..core.pagination import SyncPager
from ..types.evaluation_response import EvaluationResponse
from ..types.paginated_evaluation_response import PaginatedEvaluationResponse
from ..core.unchecked_base_model import construct_type
from ..errors.unprocessable_entity_error import UnprocessableEntityError
from ..types.http_validation_error import HttpValidationError
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from .requests.create_evaluation_request_evaluators_item import CreateEvaluationRequestEvaluatorsItemParams
from ..requests.file_request import FileRequestParams
from ..core.serialization import convert_and_respect_annotation_metadata
from .requests.add_evaluators_request_evaluators_item import AddEvaluatorsRequestEvaluatorsItemParams
from ..core.jsonable_encoder import jsonable_encoder
from ..types.evaluation_runs_response import EvaluationRunsResponse
from .requests.create_run_request_dataset import CreateRunRequestDatasetParams
from .requests.create_run_request_version import CreateRunRequestVersionParams
from ..types.evaluation_run_response import EvaluationRunResponse
from ..types.evaluation_status import EvaluationStatus
from ..types.evaluation_stats import EvaluationStats
from ..types.paginated_data_evaluation_log_response import PaginatedDataEvaluationLogResponse
from ..core.client_wrapper import AsyncClientWrapper
from ..core.pagination import AsyncPager

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class EvaluationsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(
        self,
        *,
        file_id: str,
        page: typing.Optional[int] = None,
        size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SyncPager[EvaluationResponse]:
        """
        Retrieve a list of Evaluations for the specified File.

        Parameters
        ----------
        file_id : str
            Filter by File ID. Only Evaluations for the specified File will be returned.

        page : typing.Optional[int]
            Page number for pagination.

        size : typing.Optional[int]
            Page size for pagination. Number of Evaluations to fetch.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SyncPager[EvaluationResponse]
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        response = client.evaluations.list(
            file_id="pr_30gco7dx6JDq4200GVOHa",
            size=1,
        )
        for item in response:
            yield item
        # alternatively, you can paginate page-by-page
        for page in response.iter_pages():
            yield page
        """
        page = page if page is not None else 1
        _response = self._client_wrapper.httpx_client.request(
            "evaluations",
            method="GET",
            params={
                "file_id": file_id,
                "page": page,
                "size": size,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _parsed_response = typing.cast(
                    PaginatedEvaluationResponse,
                    construct_type(
                        type_=PaginatedEvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                _has_next = True
                _get_next = lambda: self.list(
                    file_id=file_id,
                    page=page + 1,
                    size=size,
                    request_options=request_options,
                )
                _items = _parsed_response.records
                return SyncPager(has_next=_has_next, items=_items, get_next=_get_next)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create(
        self,
        *,
        evaluators: typing.Sequence[CreateEvaluationRequestEvaluatorsItemParams],
        file: typing.Optional[FileRequestParams] = OMIT,
        name: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationResponse:
        """
        Create an Evaluation.

        Create a new Evaluation by specifying the File to evaluate, and a name
        for the Evaluation.
        You can then add Runs to this Evaluation using the `POST /evaluations/{id}/runs` endpoint.

        Parameters
        ----------
        evaluators : typing.Sequence[CreateEvaluationRequestEvaluatorsItemParams]
            The Evaluators used to evaluate.

        file : typing.Optional[FileRequestParams]
            The File to associate with the Evaluation. This File contains the Logs you're evaluating.

        name : typing.Optional[str]
            Name of the Evaluation to help identify it. Must be unique within the associated File.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.create(
            evaluators=[{"version_id": "version_id"}],
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "evaluations",
            method="POST",
            json={
                "file": convert_and_respect_annotation_metadata(
                    object_=file, annotation=FileRequestParams, direction="write"
                ),
                "name": name,
                "evaluators": convert_and_respect_annotation_metadata(
                    object_=evaluators,
                    annotation=typing.Sequence[CreateEvaluationRequestEvaluatorsItemParams],
                    direction="write",
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationResponse,
                    construct_type(
                        type_=EvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def add_evaluators(
        self,
        id: str,
        *,
        evaluators: typing.Sequence[AddEvaluatorsRequestEvaluatorsItemParams],
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationResponse:
        """
        Add Evaluators to an Evaluation.

        The Evaluators will be run on the Logs generated for the Evaluation.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        evaluators : typing.Sequence[AddEvaluatorsRequestEvaluatorsItemParams]
            The Evaluators to add to this Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.add_evaluators(
            id="id",
            evaluators=[{"version_id": "version_id"}],
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/evaluators",
            method="POST",
            json={
                "evaluators": convert_and_respect_annotation_metadata(
                    object_=evaluators,
                    annotation=typing.Sequence[AddEvaluatorsRequestEvaluatorsItemParams],
                    direction="write",
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationResponse,
                    construct_type(
                        type_=EvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def remove_evaluator(
        self, id: str, evaluator_version_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluationResponse:
        """
        Remove an Evaluator from an Evaluation.

        The Evaluator will no longer be run on the Logs in the Evaluation.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        evaluator_version_id : str
            Unique identifier for Evaluator Version.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.remove_evaluator(
            id="id",
            evaluator_version_id="evaluator_version_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/evaluators/{jsonable_encoder(evaluator_version_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationResponse,
                    construct_type(
                        type_=EvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> EvaluationResponse:
        """
        Get an Evaluation.

        This includes the Evaluators associated with the Evaluation and metadata about the Evaluation,
        such as its name.

        To get the Runs associated with the Evaluation, use the `GET /evaluations/{id}/runs` endpoint.
        To retrieve stats for the Evaluation, use the `GET /evaluations/{id}/stats` endpoint.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.get(
            id="ev_567yza",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationResponse,
                    construct_type(
                        type_=EvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete an Evaluation.

        The Runs and Evaluators in the Evaluation will not be deleted.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.delete(
            id="ev_567yza",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_runs_for_evaluation(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluationRunsResponse:
        """
        List all Runs for an Evaluation.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationRunsResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.list_runs_for_evaluation(
            id="id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationRunsResponse,
                    construct_type(
                        type_=EvaluationRunsResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_run(
        self,
        id: str,
        *,
        dataset: typing.Optional[CreateRunRequestDatasetParams] = OMIT,
        version: typing.Optional[CreateRunRequestVersionParams] = OMIT,
        orchestrated: typing.Optional[bool] = OMIT,
        use_existing_logs: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationRunResponse:
        """
        Create an Evaluation Run.

        Optionally specify the Dataset and version to be evaluated.

        Humanloop will automatically start generating Logs and running Evaluators where
        `orchestrated=true`. If you are generating Logs yourself, you can set `orchestrated=false`
        and then generate and submit the required Logs via the API.

        If `dataset` and `version` are provided, you can set `use_existing_logs=True` to reuse existing Logs,
        avoiding generating new Logs unnecessarily. Logs that are associated with the specified Version and have `source_datapoint_id`
        referencing a datapoint in the specified Dataset will be associated with the Run.

        To keep updated on the progress of the Run, you can poll the Run using
        the `GET /evaluations/{id}/runs` endpoint and check its status.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        dataset : typing.Optional[CreateRunRequestDatasetParams]
            Dataset to use in this Run.

        version : typing.Optional[CreateRunRequestVersionParams]
            Version to use in this Run.

        orchestrated : typing.Optional[bool]
            Whether the Run is orchestrated by Humanloop. If `True`, Humanloop will generate Logs for the Run; `dataset` and `version` must be provided. If `False`, a log for the Prompt/Tool should be submitted by the user via the API.

        use_existing_logs : typing.Optional[bool]
            If `True`, the Run will be initialized with existing Logs associated with the Dataset and Version. If `False`, the Run will be initialized with no Logs. Can only be set to `True` when both `dataset` and `version` are provided.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationRunResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.create_run(
            id="id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs",
            method="POST",
            json={
                "dataset": convert_and_respect_annotation_metadata(
                    object_=dataset, annotation=CreateRunRequestDatasetParams, direction="write"
                ),
                "version": convert_and_respect_annotation_metadata(
                    object_=version, annotation=CreateRunRequestVersionParams, direction="write"
                ),
                "orchestrated": orchestrated,
                "use_existing_logs": use_existing_logs,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationRunResponse,
                    construct_type(
                        type_=EvaluationRunResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def add_existing_run(
        self, id: str, run_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.Optional[typing.Any]:
        """
        Add an existing Run to the specified Evaluation.

        This is useful if you want to compare the Runs in this Evaluation with an existing Run
        that exists within another Evaluation.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        run_id : str
            Unique identifier for Run.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.add_existing_run(
            id="id",
            run_id="run_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs/{jsonable_encoder(run_id)}",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def remove_run(self, id: str, run_id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Remove a Run from an Evaluation.

        The Logs and Versions used in the Run will not be deleted.
        If this Run is used in any other Evaluations, it will still be available in those Evaluations.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        run_id : str
            Unique identifier for Run.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.remove_run(
            id="id",
            run_id="run_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs/{jsonable_encoder(run_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_evaluation_run(
        self,
        id: str,
        run_id: str,
        *,
        control: typing.Optional[bool] = OMIT,
        status: typing.Optional[EvaluationStatus] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationRunResponse:
        """
        Update an Evaluation Run.

        Specify `control=true` to use this Run as the control Run for the Evaluation.
        You can cancel a running/pending Run, or mark a Run that uses external or human Evaluators as completed.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        run_id : str
            Unique identifier for Run.

        control : typing.Optional[bool]
            If `True`, this Run will be used as the control in the Evaluation. Stats for other Runs will be compared to this Run. This will replace any existing control Run.

        status : typing.Optional[EvaluationStatus]
            Used to set the Run to `cancelled` or `completed`. Can only be used if the Run is currently `pending` or `running`.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationRunResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.update_evaluation_run(
            id="id",
            run_id="run_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs/{jsonable_encoder(run_id)}",
            method="PATCH",
            json={
                "control": control,
                "status": status,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationRunResponse,
                    construct_type(
                        type_=EvaluationRunResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def add_logs_to_run(
        self,
        id: str,
        run_id: str,
        *,
        log_ids: typing.Sequence[str],
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationRunResponse:
        """
        Add the specified Logs to a Run.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        run_id : str
            Unique identifier for Run.

        log_ids : typing.Sequence[str]
            The IDs of the Logs to add to the Run.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationRunResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.add_logs_to_run(
            id="id",
            run_id="run_id",
            log_ids=["log_ids"],
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs/{jsonable_encoder(run_id)}/logs",
            method="POST",
            json={
                "log_ids": log_ids,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationRunResponse,
                    construct_type(
                        type_=EvaluationRunResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_stats(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> EvaluationStats:
        """
        Get Evaluation Stats.

        Retrieve aggregate stats for the specified Evaluation. This includes the number of generated Logs for each Run and the
        corresponding Evaluator statistics (such as the mean and percentiles).

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationStats
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.get_stats(
            id="id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/stats",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationStats,
                    construct_type(
                        type_=EvaluationStats,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_logs(
        self,
        id: str,
        *,
        page: typing.Optional[int] = None,
        size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedDataEvaluationLogResponse:
        """
        Get the Logs associated to a specific Evaluation.

        This returns the Logs associated to all Runs within with the Evaluation.

        Parameters
        ----------
        id : str
            String ID of evaluation. Starts with `ev_` or `evr_`.

        page : typing.Optional[int]
            Page number for pagination.

        size : typing.Optional[int]
            Page size for pagination. Number of Logs to fetch.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedDataEvaluationLogResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluations.get_logs(
            id="id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/logs",
            method="GET",
            params={
                "page": page,
                "size": size,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    PaginatedDataEvaluationLogResponse,
                    construct_type(
                        type_=PaginatedDataEvaluationLogResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncEvaluationsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(
        self,
        *,
        file_id: str,
        page: typing.Optional[int] = None,
        size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncPager[EvaluationResponse]:
        """
        Retrieve a list of Evaluations for the specified File.

        Parameters
        ----------
        file_id : str
            Filter by File ID. Only Evaluations for the specified File will be returned.

        page : typing.Optional[int]
            Page number for pagination.

        size : typing.Optional[int]
            Page size for pagination. Number of Evaluations to fetch.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncPager[EvaluationResponse]
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            response = await client.evaluations.list(
                file_id="pr_30gco7dx6JDq4200GVOHa",
                size=1,
            )
            async for item in response:
                yield item
            # alternatively, you can paginate page-by-page
            async for page in response.iter_pages():
                yield page


        asyncio.run(main())
        """
        page = page if page is not None else 1
        _response = await self._client_wrapper.httpx_client.request(
            "evaluations",
            method="GET",
            params={
                "file_id": file_id,
                "page": page,
                "size": size,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _parsed_response = typing.cast(
                    PaginatedEvaluationResponse,
                    construct_type(
                        type_=PaginatedEvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                _has_next = True
                _get_next = lambda: self.list(
                    file_id=file_id,
                    page=page + 1,
                    size=size,
                    request_options=request_options,
                )
                _items = _parsed_response.records
                return AsyncPager(has_next=_has_next, items=_items, get_next=_get_next)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create(
        self,
        *,
        evaluators: typing.Sequence[CreateEvaluationRequestEvaluatorsItemParams],
        file: typing.Optional[FileRequestParams] = OMIT,
        name: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationResponse:
        """
        Create an Evaluation.

        Create a new Evaluation by specifying the File to evaluate, and a name
        for the Evaluation.
        You can then add Runs to this Evaluation using the `POST /evaluations/{id}/runs` endpoint.

        Parameters
        ----------
        evaluators : typing.Sequence[CreateEvaluationRequestEvaluatorsItemParams]
            The Evaluators used to evaluate.

        file : typing.Optional[FileRequestParams]
            The File to associate with the Evaluation. This File contains the Logs you're evaluating.

        name : typing.Optional[str]
            Name of the Evaluation to help identify it. Must be unique within the associated File.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.create(
                evaluators=[{"version_id": "version_id"}],
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "evaluations",
            method="POST",
            json={
                "file": convert_and_respect_annotation_metadata(
                    object_=file, annotation=FileRequestParams, direction="write"
                ),
                "name": name,
                "evaluators": convert_and_respect_annotation_metadata(
                    object_=evaluators,
                    annotation=typing.Sequence[CreateEvaluationRequestEvaluatorsItemParams],
                    direction="write",
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationResponse,
                    construct_type(
                        type_=EvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def add_evaluators(
        self,
        id: str,
        *,
        evaluators: typing.Sequence[AddEvaluatorsRequestEvaluatorsItemParams],
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationResponse:
        """
        Add Evaluators to an Evaluation.

        The Evaluators will be run on the Logs generated for the Evaluation.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        evaluators : typing.Sequence[AddEvaluatorsRequestEvaluatorsItemParams]
            The Evaluators to add to this Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.add_evaluators(
                id="id",
                evaluators=[{"version_id": "version_id"}],
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/evaluators",
            method="POST",
            json={
                "evaluators": convert_and_respect_annotation_metadata(
                    object_=evaluators,
                    annotation=typing.Sequence[AddEvaluatorsRequestEvaluatorsItemParams],
                    direction="write",
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationResponse,
                    construct_type(
                        type_=EvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def remove_evaluator(
        self, id: str, evaluator_version_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluationResponse:
        """
        Remove an Evaluator from an Evaluation.

        The Evaluator will no longer be run on the Logs in the Evaluation.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        evaluator_version_id : str
            Unique identifier for Evaluator Version.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.remove_evaluator(
                id="id",
                evaluator_version_id="evaluator_version_id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/evaluators/{jsonable_encoder(evaluator_version_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationResponse,
                    construct_type(
                        type_=EvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> EvaluationResponse:
        """
        Get an Evaluation.

        This includes the Evaluators associated with the Evaluation and metadata about the Evaluation,
        such as its name.

        To get the Runs associated with the Evaluation, use the `GET /evaluations/{id}/runs` endpoint.
        To retrieve stats for the Evaluation, use the `GET /evaluations/{id}/stats` endpoint.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.get(
                id="ev_567yza",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationResponse,
                    construct_type(
                        type_=EvaluationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete an Evaluation.

        The Runs and Evaluators in the Evaluation will not be deleted.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.delete(
                id="ev_567yza",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_runs_for_evaluation(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluationRunsResponse:
        """
        List all Runs for an Evaluation.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationRunsResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.list_runs_for_evaluation(
                id="id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationRunsResponse,
                    construct_type(
                        type_=EvaluationRunsResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_run(
        self,
        id: str,
        *,
        dataset: typing.Optional[CreateRunRequestDatasetParams] = OMIT,
        version: typing.Optional[CreateRunRequestVersionParams] = OMIT,
        orchestrated: typing.Optional[bool] = OMIT,
        use_existing_logs: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationRunResponse:
        """
        Create an Evaluation Run.

        Optionally specify the Dataset and version to be evaluated.

        Humanloop will automatically start generating Logs and running Evaluators where
        `orchestrated=true`. If you are generating Logs yourself, you can set `orchestrated=false`
        and then generate and submit the required Logs via the API.

        If `dataset` and `version` are provided, you can set `use_existing_logs=True` to reuse existing Logs,
        avoiding generating new Logs unnecessarily. Logs that are associated with the specified Version and have `source_datapoint_id`
        referencing a datapoint in the specified Dataset will be associated with the Run.

        To keep updated on the progress of the Run, you can poll the Run using
        the `GET /evaluations/{id}/runs` endpoint and check its status.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        dataset : typing.Optional[CreateRunRequestDatasetParams]
            Dataset to use in this Run.

        version : typing.Optional[CreateRunRequestVersionParams]
            Version to use in this Run.

        orchestrated : typing.Optional[bool]
            Whether the Run is orchestrated by Humanloop. If `True`, Humanloop will generate Logs for the Run; `dataset` and `version` must be provided. If `False`, a log for the Prompt/Tool should be submitted by the user via the API.

        use_existing_logs : typing.Optional[bool]
            If `True`, the Run will be initialized with existing Logs associated with the Dataset and Version. If `False`, the Run will be initialized with no Logs. Can only be set to `True` when both `dataset` and `version` are provided.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationRunResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.create_run(
                id="id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs",
            method="POST",
            json={
                "dataset": convert_and_respect_annotation_metadata(
                    object_=dataset, annotation=CreateRunRequestDatasetParams, direction="write"
                ),
                "version": convert_and_respect_annotation_metadata(
                    object_=version, annotation=CreateRunRequestVersionParams, direction="write"
                ),
                "orchestrated": orchestrated,
                "use_existing_logs": use_existing_logs,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationRunResponse,
                    construct_type(
                        type_=EvaluationRunResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def add_existing_run(
        self, id: str, run_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.Optional[typing.Any]:
        """
        Add an existing Run to the specified Evaluation.

        This is useful if you want to compare the Runs in this Evaluation with an existing Run
        that exists within another Evaluation.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        run_id : str
            Unique identifier for Run.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.Optional[typing.Any]
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.add_existing_run(
                id="id",
                run_id="run_id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs/{jsonable_encoder(run_id)}",
            method="POST",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.Optional[typing.Any],
                    construct_type(
                        type_=typing.Optional[typing.Any],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def remove_run(
        self, id: str, run_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Remove a Run from an Evaluation.

        The Logs and Versions used in the Run will not be deleted.
        If this Run is used in any other Evaluations, it will still be available in those Evaluations.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        run_id : str
            Unique identifier for Run.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.remove_run(
                id="id",
                run_id="run_id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs/{jsonable_encoder(run_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_evaluation_run(
        self,
        id: str,
        run_id: str,
        *,
        control: typing.Optional[bool] = OMIT,
        status: typing.Optional[EvaluationStatus] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationRunResponse:
        """
        Update an Evaluation Run.

        Specify `control=true` to use this Run as the control Run for the Evaluation.
        You can cancel a running/pending Run, or mark a Run that uses external or human Evaluators as completed.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        run_id : str
            Unique identifier for Run.

        control : typing.Optional[bool]
            If `True`, this Run will be used as the control in the Evaluation. Stats for other Runs will be compared to this Run. This will replace any existing control Run.

        status : typing.Optional[EvaluationStatus]
            Used to set the Run to `cancelled` or `completed`. Can only be used if the Run is currently `pending` or `running`.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationRunResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.update_evaluation_run(
                id="id",
                run_id="run_id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs/{jsonable_encoder(run_id)}",
            method="PATCH",
            json={
                "control": control,
                "status": status,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationRunResponse,
                    construct_type(
                        type_=EvaluationRunResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def add_logs_to_run(
        self,
        id: str,
        run_id: str,
        *,
        log_ids: typing.Sequence[str],
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluationRunResponse:
        """
        Add the specified Logs to a Run.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        run_id : str
            Unique identifier for Run.

        log_ids : typing.Sequence[str]
            The IDs of the Logs to add to the Run.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationRunResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.add_logs_to_run(
                id="id",
                run_id="run_id",
                log_ids=["log_ids"],
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/runs/{jsonable_encoder(run_id)}/logs",
            method="POST",
            json={
                "log_ids": log_ids,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationRunResponse,
                    construct_type(
                        type_=EvaluationRunResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_stats(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> EvaluationStats:
        """
        Get Evaluation Stats.

        Retrieve aggregate stats for the specified Evaluation. This includes the number of generated Logs for each Run and the
        corresponding Evaluator statistics (such as the mean and percentiles).

        Parameters
        ----------
        id : str
            Unique identifier for Evaluation.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluationStats
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.get_stats(
                id="id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/stats",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluationStats,
                    construct_type(
                        type_=EvaluationStats,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_logs(
        self,
        id: str,
        *,
        page: typing.Optional[int] = None,
        size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedDataEvaluationLogResponse:
        """
        Get the Logs associated to a specific Evaluation.

        This returns the Logs associated to all Runs within with the Evaluation.

        Parameters
        ----------
        id : str
            String ID of evaluation. Starts with `ev_` or `evr_`.

        page : typing.Optional[int]
            Page number for pagination.

        size : typing.Optional[int]
            Page size for pagination. Number of Logs to fetch.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedDataEvaluationLogResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluations.get_logs(
                id="id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluations/{jsonable_encoder(id)}/logs",
            method="GET",
            params={
                "page": page,
                "size": size,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    PaginatedDataEvaluationLogResponse,
                    construct_type(
                        type_=PaginatedDataEvaluationLogResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
