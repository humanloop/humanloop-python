# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing_extensions
import datetime as dt
from .chat_message import ChatMessageParams


class PromptCallLogResponseParams(typing_extensions.TypedDict):
    """
    Sample specific response details for a Prompt call
    """

    output: typing_extensions.NotRequired[str]
    """
    Generated output from your model for the provided inputs. Can be `None` if logging an error, or if creating a parent Log with the intention to populate it later.
    """

    created_at: typing_extensions.NotRequired[dt.datetime]
    """
    User defined timestamp for when the log was created.
    """

    error: typing_extensions.NotRequired[str]
    """
    Error message if the log is an error.
    """

    provider_latency: typing_extensions.NotRequired[float]
    """
    Duration of the logged event in seconds.
    """

    stdout: typing_extensions.NotRequired[str]
    """
    Captured log and debug statements.
    """

    output_message: typing_extensions.NotRequired[ChatMessageParams]
    """
    The message returned by the provider.
    """

    prompt_tokens: typing_extensions.NotRequired[int]
    """
    Number of tokens in the prompt used to generate the output.
    """

    output_tokens: typing_extensions.NotRequired[int]
    """
    Number of tokens in the output generated by the model.
    """

    prompt_cost: typing_extensions.NotRequired[float]
    """
    Cost in dollars associated to the tokens in the prompt.
    """

    output_cost: typing_extensions.NotRequired[float]
    """
    Cost in dollars associated to the tokens in the output.
    """

    finish_reason: typing_extensions.NotRequired[str]
    """
    Reason the generation finished.
    """

    index: int
    """
    The index of the sample in the batch.
    """
