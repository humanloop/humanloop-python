# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing_extensions
from .run_version_response import RunVersionResponseParams
import datetime as dt


class EvaluateeResponseParams(typing_extensions.TypedDict):
    """
    Version of the Evaluatee being evaluated.
    """

    version: typing_extensions.NotRequired[RunVersionResponseParams]
    batch_id: typing_extensions.NotRequired[str]
    """
    Unique identifier for the batch of Logs to include in the Evaluation.
    """

    orchestrated: bool
    """
    Whether the Prompt/Tool is orchestrated by Humanloop. Default is `True`. If `False`, a log for the Prompt/Tool should be submitted by the user via the API.
    """

    pinned: bool
    """
    Pinned Evaluatees are shown in Humanloop's Overview, allowing you to use them as baselines for comparison.
    """

    added_at: typing_extensions.NotRequired[dt.datetime]
    """
    When the Evaluatee was added to the Evaluation.
    """
