# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from .raw_client import RawAgentsClient
from ..requests.chat_message import ChatMessageParams
from .requests.agent_log_request_tool_choice import AgentLogRequestToolChoiceParams
from ..requests.agent_kernel_request import AgentKernelRequestParams
import datetime as dt
from ..types.log_status import LogStatus
from ..core.request_options import RequestOptions
from ..types.create_agent_log_response import CreateAgentLogResponse
from ..types.log_response import LogResponse
from .requests.agents_call_stream_request_tool_choice import AgentsCallStreamRequestToolChoiceParams
from ..requests.provider_api_keys import ProviderApiKeysParams
from ..types.agent_call_stream_response import AgentCallStreamResponse
from .requests.agents_call_request_tool_choice import AgentsCallRequestToolChoiceParams
from ..types.agent_call_response import AgentCallResponse
from ..types.agent_continue_stream_response import AgentContinueStreamResponse
from ..types.agent_continue_response import AgentContinueResponse
from ..types.project_sort_by import ProjectSortBy
from ..types.sort_order import SortOrder
from ..types.paginated_data_agent_response import PaginatedDataAgentResponse
from ..types.model_endpoints import ModelEndpoints
from .requests.agent_request_template import AgentRequestTemplateParams
from ..types.template_language import TemplateLanguage
from ..types.model_providers import ModelProviders
from .requests.agent_request_stop import AgentRequestStopParams
from ..requests.response_format import ResponseFormatParams
from .requests.agent_request_reasoning_effort import AgentRequestReasoningEffortParams
from .requests.agent_request_tools_item import AgentRequestToolsItemParams
from ..types.agent_response import AgentResponse
from ..types.list_agents import ListAgents
from ..types.file_environment_response import FileEnvironmentResponse
from ..requests.evaluator_activation_deactivation_request_activate_item import (
    EvaluatorActivationDeactivationRequestActivateItemParams,
)
from ..requests.evaluator_activation_deactivation_request_deactivate_item import (
    EvaluatorActivationDeactivationRequestDeactivateItemParams,
)
from ..types.agent_kernel_request import AgentKernelRequest
from ..core.client_wrapper import AsyncClientWrapper
from .raw_client import AsyncRawAgentsClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class AgentsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawAgentsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawAgentsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawAgentsClient
        """
        return self._raw_client

    def log(
        self,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        run_id: typing.Optional[str] = OMIT,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        output_message: typing.Optional[ChatMessageParams] = OMIT,
        prompt_tokens: typing.Optional[int] = OMIT,
        reasoning_tokens: typing.Optional[int] = OMIT,
        output_tokens: typing.Optional[int] = OMIT,
        prompt_cost: typing.Optional[float] = OMIT,
        output_cost: typing.Optional[float] = OMIT,
        finish_reason: typing.Optional[str] = OMIT,
        messages: typing.Optional[typing.Sequence[ChatMessageParams]] = OMIT,
        tool_choice: typing.Optional[AgentLogRequestToolChoiceParams] = OMIT,
        agent: typing.Optional[AgentKernelRequestParams] = OMIT,
        start_time: typing.Optional[dt.datetime] = OMIT,
        end_time: typing.Optional[dt.datetime] = OMIT,
        output: typing.Optional[str] = OMIT,
        created_at: typing.Optional[dt.datetime] = OMIT,
        error: typing.Optional[str] = OMIT,
        provider_latency: typing.Optional[float] = OMIT,
        stdout: typing.Optional[str] = OMIT,
        provider_request: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        provider_response: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        log_status: typing.Optional[LogStatus] = OMIT,
        source_datapoint_id: typing.Optional[str] = OMIT,
        trace_parent_id: typing.Optional[str] = OMIT,
        user: typing.Optional[str] = OMIT,
        agent_log_request_environment: typing.Optional[str] = OMIT,
        save: typing.Optional[bool] = OMIT,
        log_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CreateAgentLogResponse:
        """
        Create an Agent Log.

        You can use query parameters `version_id`, or `environment`, to target
        an existing version of the Agent. Otherwise, the default deployed version will be chosen.

        If you create the Agent Log with a `log_status` of `incomplete`, you should later update it to `complete`
        in order to trigger Evaluators.

        Parameters
        ----------
        version_id : typing.Optional[str]
            A specific Version ID of the Agent to log to.

        environment : typing.Optional[str]
            Name of the Environment identifying a deployed version to log to.

        run_id : typing.Optional[str]
            Unique identifier for the Run to associate the Log to.

        path : typing.Optional[str]
            Path of the Agent, including the name. This locates the Agent in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Agent.

        output_message : typing.Optional[ChatMessageParams]
            The message returned by the provider.

        prompt_tokens : typing.Optional[int]
            Number of tokens in the prompt used to generate the output.

        reasoning_tokens : typing.Optional[int]
            Number of reasoning tokens used to generate the output.

        output_tokens : typing.Optional[int]
            Number of tokens in the output generated by the model.

        prompt_cost : typing.Optional[float]
            Cost in dollars associated to the tokens in the prompt.

        output_cost : typing.Optional[float]
            Cost in dollars associated to the tokens in the output.

        finish_reason : typing.Optional[str]
            Reason the generation finished.

        messages : typing.Optional[typing.Sequence[ChatMessageParams]]
            The messages passed to the to provider chat endpoint.

        tool_choice : typing.Optional[AgentLogRequestToolChoiceParams]
            Controls how the model uses tools. The following options are supported:
            - `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt.
            - `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt.
            - `'required'` means the model must call one or more of the provided tools.
            - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.

        agent : typing.Optional[AgentKernelRequestParams]
            Details of your Agent. A new Agent version will be created if the provided details are new.

        start_time : typing.Optional[dt.datetime]
            When the logged event started.

        end_time : typing.Optional[dt.datetime]
            When the logged event ended.

        output : typing.Optional[str]
            Generated output from your model for the provided inputs. Can be `None` if logging an error, or if creating a parent Log with the intention to populate it later.

        created_at : typing.Optional[dt.datetime]
            User defined timestamp for when the log was created.

        error : typing.Optional[str]
            Error message if the log is an error.

        provider_latency : typing.Optional[float]
            Duration of the logged event in seconds.

        stdout : typing.Optional[str]
            Captured log and debug statements.

        provider_request : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Raw request sent to provider.

        provider_response : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Raw response received the provider.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the prompt template.

        source : typing.Optional[str]
            Identifies where the model was called from.

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Any additional metadata to record.

        log_status : typing.Optional[LogStatus]
            Status of a Log. Set to `incomplete` if you intend to update and eventually complete the Log and want the File's monitoring Evaluators to wait until you mark it as `complete`. If log_status is not provided, observability will pick up the Log as soon as possible. Updating this from specified to unspecified is undefined behavior.

        source_datapoint_id : typing.Optional[str]
            Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.

        trace_parent_id : typing.Optional[str]
            The ID of the parent Log to nest this Log under in a Trace.

        user : typing.Optional[str]
            End-user ID related to the Log.

        agent_log_request_environment : typing.Optional[str]
            The name of the Environment the Log is associated to.

        save : typing.Optional[bool]
            Whether the request/response payloads will be stored on Humanloop.

        log_id : typing.Optional[str]
            This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CreateAgentLogResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.log()
        """
        response = self._raw_client.log(
            version_id=version_id,
            environment=environment,
            run_id=run_id,
            path=path,
            id=id,
            output_message=output_message,
            prompt_tokens=prompt_tokens,
            reasoning_tokens=reasoning_tokens,
            output_tokens=output_tokens,
            prompt_cost=prompt_cost,
            output_cost=output_cost,
            finish_reason=finish_reason,
            messages=messages,
            tool_choice=tool_choice,
            agent=agent,
            start_time=start_time,
            end_time=end_time,
            output=output,
            created_at=created_at,
            error=error,
            provider_latency=provider_latency,
            stdout=stdout,
            provider_request=provider_request,
            provider_response=provider_response,
            inputs=inputs,
            source=source,
            metadata=metadata,
            log_status=log_status,
            source_datapoint_id=source_datapoint_id,
            trace_parent_id=trace_parent_id,
            user=user,
            agent_log_request_environment=agent_log_request_environment,
            save=save,
            log_id=log_id,
            request_options=request_options,
        )
        return response.data

    def update_log(
        self,
        id: str,
        log_id: str,
        *,
        messages: typing.Optional[typing.Sequence[ChatMessageParams]] = OMIT,
        output_message: typing.Optional[ChatMessageParams] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        output: typing.Optional[str] = OMIT,
        error: typing.Optional[str] = OMIT,
        log_status: typing.Optional[LogStatus] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> LogResponse:
        """
        Update a Log.

        Update the details of a Log with the given ID.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        log_id : str
            Unique identifier for the Log.

        messages : typing.Optional[typing.Sequence[ChatMessageParams]]
            List of chat messages that were used as an input to the Flow.

        output_message : typing.Optional[ChatMessageParams]
            The output message returned by this Flow.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the Flow Log.

        output : typing.Optional[str]
            The output of the Flow Log. Provide None to unset existing `output` value. Provide either this, `output_message` or `error`.

        error : typing.Optional[str]
            The error message of the Flow Log. Provide None to unset existing `error` value. Provide either this, `output_message` or `output`.

        log_status : typing.Optional[LogStatus]
            Status of the Flow Log. When a Flow Log is updated to `complete`, no more Logs can be added to it. Monitoring Evaluators will only run on `complete` Flow Logs.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        LogResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.update_log(
            id="id",
            log_id="log_id",
        )
        """
        response = self._raw_client.update_log(
            id,
            log_id,
            messages=messages,
            output_message=output_message,
            inputs=inputs,
            output=output,
            error=error,
            log_status=log_status,
            request_options=request_options,
        )
        return response.data

    def call_stream(
        self,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        messages: typing.Optional[typing.Sequence[ChatMessageParams]] = OMIT,
        tool_choice: typing.Optional[AgentsCallStreamRequestToolChoiceParams] = OMIT,
        agent: typing.Optional[AgentKernelRequestParams] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        start_time: typing.Optional[dt.datetime] = OMIT,
        end_time: typing.Optional[dt.datetime] = OMIT,
        log_status: typing.Optional[LogStatus] = OMIT,
        source_datapoint_id: typing.Optional[str] = OMIT,
        trace_parent_id: typing.Optional[str] = OMIT,
        user: typing.Optional[str] = OMIT,
        agents_call_stream_request_environment: typing.Optional[str] = OMIT,
        save: typing.Optional[bool] = OMIT,
        log_id: typing.Optional[str] = OMIT,
        provider_api_keys: typing.Optional[ProviderApiKeysParams] = OMIT,
        return_inputs: typing.Optional[bool] = OMIT,
        include_trace_children: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Iterator[AgentCallStreamResponse]:
        """
        Call an Agent.

        Calling an Agent calls the model provider before logging
        the request, responses and metadata to Humanloop.

        You can use query parameters `version_id`, or `environment`, to target
        an existing version of the Agent. Otherwise the default deployed version will be chosen.

        Instead of targeting an existing version explicitly, you can instead pass in
        Agent details in the request body. In this case, we will check if the details correspond
        to an existing version of the Agent. If they do not, we will create a new version. This is helpful
        in the case where you are storing or deriving your Agent details in code.

        Parameters
        ----------
        version_id : typing.Optional[str]
            A specific Version ID of the Agent to log to.

        environment : typing.Optional[str]
            Name of the Environment identifying a deployed version to log to.

        path : typing.Optional[str]
            Path of the Agent, including the name. This locates the Agent in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Agent.

        messages : typing.Optional[typing.Sequence[ChatMessageParams]]
            The messages passed to the to provider chat endpoint.

        tool_choice : typing.Optional[AgentsCallStreamRequestToolChoiceParams]
            Controls how the model uses tools. The following options are supported:
            - `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt.
            - `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt.
            - `'required'` means the model must call one or more of the provided tools.
            - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.

        agent : typing.Optional[AgentKernelRequestParams]
            Details of your Agent. A new Agent version will be created if the provided details are new.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the prompt template.

        source : typing.Optional[str]
            Identifies where the model was called from.

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Any additional metadata to record.

        start_time : typing.Optional[dt.datetime]
            When the logged event started.

        end_time : typing.Optional[dt.datetime]
            When the logged event ended.

        log_status : typing.Optional[LogStatus]
            Status of a Log. Set to `incomplete` if you intend to update and eventually complete the Log and want the File's monitoring Evaluators to wait until you mark it as `complete`. If log_status is not provided, observability will pick up the Log as soon as possible. Updating this from specified to unspecified is undefined behavior.

        source_datapoint_id : typing.Optional[str]
            Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.

        trace_parent_id : typing.Optional[str]
            The ID of the parent Log to nest this Log under in a Trace.

        user : typing.Optional[str]
            End-user ID related to the Log.

        agents_call_stream_request_environment : typing.Optional[str]
            The name of the Environment the Log is associated to.

        save : typing.Optional[bool]
            Whether the request/response payloads will be stored on Humanloop.

        log_id : typing.Optional[str]
            This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.

        provider_api_keys : typing.Optional[ProviderApiKeysParams]
            API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization.

        return_inputs : typing.Optional[bool]
            Whether to return the inputs in the response. If false, the response will contain an empty dictionary under inputs. This is useful for reducing the size of the response. Defaults to true.

        include_trace_children : typing.Optional[bool]
            If true, populate `trace_children` for the returned Agent Log. Only applies when not streaming. Defaults to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.Iterator[AgentCallStreamResponse]


        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        response = client.agents.call_stream()
        for chunk in response:
            yield chunk
        """
        with self._raw_client.call_stream(
            version_id=version_id,
            environment=environment,
            path=path,
            id=id,
            messages=messages,
            tool_choice=tool_choice,
            agent=agent,
            inputs=inputs,
            source=source,
            metadata=metadata,
            start_time=start_time,
            end_time=end_time,
            log_status=log_status,
            source_datapoint_id=source_datapoint_id,
            trace_parent_id=trace_parent_id,
            user=user,
            agents_call_stream_request_environment=agents_call_stream_request_environment,
            save=save,
            log_id=log_id,
            provider_api_keys=provider_api_keys,
            return_inputs=return_inputs,
            include_trace_children=include_trace_children,
            request_options=request_options,
        ) as r:
            yield from r.data

    def call(
        self,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        messages: typing.Optional[typing.Sequence[ChatMessageParams]] = OMIT,
        tool_choice: typing.Optional[AgentsCallRequestToolChoiceParams] = OMIT,
        agent: typing.Optional[AgentKernelRequestParams] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        start_time: typing.Optional[dt.datetime] = OMIT,
        end_time: typing.Optional[dt.datetime] = OMIT,
        log_status: typing.Optional[LogStatus] = OMIT,
        source_datapoint_id: typing.Optional[str] = OMIT,
        trace_parent_id: typing.Optional[str] = OMIT,
        user: typing.Optional[str] = OMIT,
        agents_call_request_environment: typing.Optional[str] = OMIT,
        save: typing.Optional[bool] = OMIT,
        log_id: typing.Optional[str] = OMIT,
        provider_api_keys: typing.Optional[ProviderApiKeysParams] = OMIT,
        return_inputs: typing.Optional[bool] = OMIT,
        include_trace_children: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentCallResponse:
        """
        Call an Agent.

        Calling an Agent calls the model provider before logging
        the request, responses and metadata to Humanloop.

        You can use query parameters `version_id`, or `environment`, to target
        an existing version of the Agent. Otherwise the default deployed version will be chosen.

        Instead of targeting an existing version explicitly, you can instead pass in
        Agent details in the request body. In this case, we will check if the details correspond
        to an existing version of the Agent. If they do not, we will create a new version. This is helpful
        in the case where you are storing or deriving your Agent details in code.

        Parameters
        ----------
        version_id : typing.Optional[str]
            A specific Version ID of the Agent to log to.

        environment : typing.Optional[str]
            Name of the Environment identifying a deployed version to log to.

        path : typing.Optional[str]
            Path of the Agent, including the name. This locates the Agent in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Agent.

        messages : typing.Optional[typing.Sequence[ChatMessageParams]]
            The messages passed to the to provider chat endpoint.

        tool_choice : typing.Optional[AgentsCallRequestToolChoiceParams]
            Controls how the model uses tools. The following options are supported:
            - `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt.
            - `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt.
            - `'required'` means the model must call one or more of the provided tools.
            - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.

        agent : typing.Optional[AgentKernelRequestParams]
            Details of your Agent. A new Agent version will be created if the provided details are new.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the prompt template.

        source : typing.Optional[str]
            Identifies where the model was called from.

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Any additional metadata to record.

        start_time : typing.Optional[dt.datetime]
            When the logged event started.

        end_time : typing.Optional[dt.datetime]
            When the logged event ended.

        log_status : typing.Optional[LogStatus]
            Status of a Log. Set to `incomplete` if you intend to update and eventually complete the Log and want the File's monitoring Evaluators to wait until you mark it as `complete`. If log_status is not provided, observability will pick up the Log as soon as possible. Updating this from specified to unspecified is undefined behavior.

        source_datapoint_id : typing.Optional[str]
            Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.

        trace_parent_id : typing.Optional[str]
            The ID of the parent Log to nest this Log under in a Trace.

        user : typing.Optional[str]
            End-user ID related to the Log.

        agents_call_request_environment : typing.Optional[str]
            The name of the Environment the Log is associated to.

        save : typing.Optional[bool]
            Whether the request/response payloads will be stored on Humanloop.

        log_id : typing.Optional[str]
            This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.

        provider_api_keys : typing.Optional[ProviderApiKeysParams]
            API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization.

        return_inputs : typing.Optional[bool]
            Whether to return the inputs in the response. If false, the response will contain an empty dictionary under inputs. This is useful for reducing the size of the response. Defaults to true.

        include_trace_children : typing.Optional[bool]
            If true, populate `trace_children` for the returned Agent Log. Only applies when not streaming. Defaults to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentCallResponse


        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.call()
        """
        response = self._raw_client.call(
            version_id=version_id,
            environment=environment,
            path=path,
            id=id,
            messages=messages,
            tool_choice=tool_choice,
            agent=agent,
            inputs=inputs,
            source=source,
            metadata=metadata,
            start_time=start_time,
            end_time=end_time,
            log_status=log_status,
            source_datapoint_id=source_datapoint_id,
            trace_parent_id=trace_parent_id,
            user=user,
            agents_call_request_environment=agents_call_request_environment,
            save=save,
            log_id=log_id,
            provider_api_keys=provider_api_keys,
            return_inputs=return_inputs,
            include_trace_children=include_trace_children,
            request_options=request_options,
        )
        return response.data

    def continue_stream(
        self,
        *,
        log_id: str,
        messages: typing.Sequence[ChatMessageParams],
        provider_api_keys: typing.Optional[ProviderApiKeysParams] = OMIT,
        include_trace_children: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Iterator[AgentContinueStreamResponse]:
        """
        Continue an incomplete Agent call.

        This endpoint allows continuing an existing incomplete Agent call, using the context
        from the previous interaction. The Agent will resume processing from where it left off.

        The original log must be in an incomplete state to be continued.

        The messages in the request will be appended
        to the original messages in the log.

        Parameters
        ----------
        log_id : str
            This identifies the Agent Log to continue.

        messages : typing.Sequence[ChatMessageParams]
            The additional messages with which to continue the Agent Log. Often, these should start with the Tool messages with results for the previous Assistant message's tool calls.

        provider_api_keys : typing.Optional[ProviderApiKeysParams]
            API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization.

        include_trace_children : typing.Optional[bool]
            If true, populate `trace_children` for the returned Agent Log. Defaults to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.Iterator[AgentContinueStreamResponse]


        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        response = client.agents.continue_stream(
            log_id="log_id",
            messages=[{"role": "user"}],
        )
        for chunk in response:
            yield chunk
        """
        with self._raw_client.continue_stream(
            log_id=log_id,
            messages=messages,
            provider_api_keys=provider_api_keys,
            include_trace_children=include_trace_children,
            request_options=request_options,
        ) as r:
            yield from r.data

    def continue_(
        self,
        *,
        log_id: str,
        messages: typing.Sequence[ChatMessageParams],
        provider_api_keys: typing.Optional[ProviderApiKeysParams] = OMIT,
        include_trace_children: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentContinueResponse:
        """
        Continue an incomplete Agent call.

        This endpoint allows continuing an existing incomplete Agent call, using the context
        from the previous interaction. The Agent will resume processing from where it left off.

        The original log must be in an incomplete state to be continued.

        The messages in the request will be appended
        to the original messages in the log.

        Parameters
        ----------
        log_id : str
            This identifies the Agent Log to continue.

        messages : typing.Sequence[ChatMessageParams]
            The additional messages with which to continue the Agent Log. Often, these should start with the Tool messages with results for the previous Assistant message's tool calls.

        provider_api_keys : typing.Optional[ProviderApiKeysParams]
            API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization.

        include_trace_children : typing.Optional[bool]
            If true, populate `trace_children` for the returned Agent Log. Defaults to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentContinueResponse


        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.continue_(
            log_id="log_id",
            messages=[{"role": "user"}],
        )
        """
        response = self._raw_client.continue_(
            log_id=log_id,
            messages=messages,
            provider_api_keys=provider_api_keys,
            include_trace_children=include_trace_children,
            request_options=request_options,
        )
        return response.data

    def list(
        self,
        *,
        page: typing.Optional[int] = None,
        size: typing.Optional[int] = None,
        name: typing.Optional[str] = None,
        user_filter: typing.Optional[str] = None,
        sort_by: typing.Optional[ProjectSortBy] = None,
        order: typing.Optional[SortOrder] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedDataAgentResponse:
        """
        Get a list of all Agents.

        Parameters
        ----------
        page : typing.Optional[int]
            Page number for pagination.

        size : typing.Optional[int]
            Page size for pagination. Number of Agents to fetch.

        name : typing.Optional[str]
            Case-insensitive filter for Agent name.

        user_filter : typing.Optional[str]
            Case-insensitive filter for users in the Agent. This filter matches against both email address and name of users.

        sort_by : typing.Optional[ProjectSortBy]
            Field to sort Agents by

        order : typing.Optional[SortOrder]
            Direction to sort by.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedDataAgentResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.list()
        """
        response = self._raw_client.list(
            page=page,
            size=size,
            name=name,
            user_filter=user_filter,
            sort_by=sort_by,
            order=order,
            request_options=request_options,
        )
        return response.data

    def upsert(
        self,
        *,
        model: str,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        endpoint: typing.Optional[ModelEndpoints] = OMIT,
        template: typing.Optional[AgentRequestTemplateParams] = OMIT,
        template_language: typing.Optional[TemplateLanguage] = OMIT,
        provider: typing.Optional[ModelProviders] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        top_p: typing.Optional[float] = OMIT,
        stop: typing.Optional[AgentRequestStopParams] = OMIT,
        presence_penalty: typing.Optional[float] = OMIT,
        frequency_penalty: typing.Optional[float] = OMIT,
        other: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        seed: typing.Optional[int] = OMIT,
        response_format: typing.Optional[ResponseFormatParams] = OMIT,
        reasoning_effort: typing.Optional[AgentRequestReasoningEffortParams] = OMIT,
        tools: typing.Optional[typing.Sequence[AgentRequestToolsItemParams]] = OMIT,
        attributes: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        max_iterations: typing.Optional[int] = OMIT,
        version_name: typing.Optional[str] = OMIT,
        version_description: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        tags: typing.Optional[typing.Sequence[str]] = OMIT,
        readme: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Create an Agent or update it with a new version if it already exists.

        Agents are identified by the `ID` or their `path`. The parameters (i.e. the template, temperature, model etc.) and
        tools determine the versions of the Agent.

        You can provide `version_name` and `version_description` to identify and describe your versions.
        Version names must be unique within an Agent - attempting to create a version with a name
        that already exists will result in a 409 Conflict error.

        Parameters
        ----------
        model : str
            The model instance used, e.g. `gpt-4`. See [supported models](https://humanloop.com/docs/reference/supported-models)

        path : typing.Optional[str]
            Path of the Agent, including the name. This locates the Agent in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Agent.

        endpoint : typing.Optional[ModelEndpoints]
            The provider model endpoint used.

        template : typing.Optional[AgentRequestTemplateParams]
            The template contains the main structure and instructions for the model, including input variables for dynamic values.

            For chat models, provide the template as a ChatTemplate (a list of messages), e.g. a system message, followed by a user message with an input variable.
            For completion models, provide a prompt template as a string.

            Input variables should be specified with double curly bracket syntax: `{{input_name}}`.

        template_language : typing.Optional[TemplateLanguage]
            The template language to use for rendering the template.

        provider : typing.Optional[ModelProviders]
            The company providing the underlying model service.

        max_tokens : typing.Optional[int]
            The maximum number of tokens to generate. Provide max_tokens=-1 to dynamically calculate the maximum number of tokens to generate given the length of the prompt

        temperature : typing.Optional[float]
            What sampling temperature to use when making a generation. Higher values means the model will be more creative.

        top_p : typing.Optional[float]
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.

        stop : typing.Optional[AgentRequestStopParams]
            The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.

        presence_penalty : typing.Optional[float]
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the generation so far.

        frequency_penalty : typing.Optional[float]
            Number between -2.0 and 2.0. Positive values penalize new tokens based on how frequently they appear in the generation so far.

        other : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Other parameter values to be passed to the provider call.

        seed : typing.Optional[int]
            If specified, model will make a best effort to sample deterministically, but it is not guaranteed.

        response_format : typing.Optional[ResponseFormatParams]
            The format of the response. Only `{"type": "json_object"}` is currently supported for chat.

        reasoning_effort : typing.Optional[AgentRequestReasoningEffortParams]
            Guidance on how many reasoning tokens it should generate before creating a response to the prompt. OpenAI reasoning models (o1, o3-mini) expect a OpenAIReasoningEffort enum. Anthropic reasoning models expect an integer, which signifies the maximum token budget.

        tools : typing.Optional[typing.Sequence[AgentRequestToolsItemParams]]

        attributes : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Additional fields to describe the Prompt. Helpful to separate Prompt versions from each other with details on how they were created or used.

        max_iterations : typing.Optional[int]
            The maximum number of iterations the Agent can run. This is used to limit the number of times the Agent model is called.

        version_name : typing.Optional[str]
            Unique name for the Prompt version. Each Prompt can only have one version with a given name.

        version_description : typing.Optional[str]
            Description of the Version.

        description : typing.Optional[str]
            Description of the Prompt.

        tags : typing.Optional[typing.Sequence[str]]
            List of tags associated with this prompt.

        readme : typing.Optional[str]
            Long description of the Prompt.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.upsert(
            model="model",
        )
        """
        response = self._raw_client.upsert(
            model=model,
            path=path,
            id=id,
            endpoint=endpoint,
            template=template,
            template_language=template_language,
            provider=provider,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            stop=stop,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty,
            other=other,
            seed=seed,
            response_format=response_format,
            reasoning_effort=reasoning_effort,
            tools=tools,
            attributes=attributes,
            max_iterations=max_iterations,
            version_name=version_name,
            version_description=version_description,
            description=description,
            tags=tags,
            readme=readme,
            request_options=request_options,
        )
        return response.data

    def delete_agent_version(
        self, id: str, version_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Delete a version of the Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        version_id : str
            Unique identifier for the specific version of the Agent.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.delete_agent_version(
            id="id",
            version_id="version_id",
        )
        """
        response = self._raw_client.delete_agent_version(id, version_id, request_options=request_options)
        return response.data

    def patch_agent_version(
        self,
        id: str,
        version_id: str,
        *,
        name: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Update the name or description of the Agent version.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        version_id : str
            Unique identifier for the specific version of the Agent.

        name : typing.Optional[str]
            Name of the version.

        description : typing.Optional[str]
            Description of the version.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.patch_agent_version(
            id="id",
            version_id="version_id",
        )
        """
        response = self._raw_client.patch_agent_version(
            id, version_id, name=name, description=description, request_options=request_options
        )
        return response.data

    def get(
        self,
        id: str,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Retrieve the Agent with the given ID.

        By default, the deployed version of the Agent is returned. Use the query parameters
        `version_id` or `environment` to target a specific version of the Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        version_id : typing.Optional[str]
            A specific Version ID of the Agent to retrieve.

        environment : typing.Optional[str]
            Name of the Environment to retrieve a deployed Version from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.get(
            id="id",
        )
        """
        response = self._raw_client.get(
            id, version_id=version_id, environment=environment, request_options=request_options
        )
        return response.data

    def delete(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete the Agent with the given ID.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.delete(
            id="id",
        )
        """
        response = self._raw_client.delete(id, request_options=request_options)
        return response.data

    def move(
        self,
        id: str,
        *,
        path: typing.Optional[str] = OMIT,
        name: typing.Optional[str] = OMIT,
        directory_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Move the Agent to a different path or change the name.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        path : typing.Optional[str]
            Path of the Flow including the Flow name, which is used as a unique identifier.

        name : typing.Optional[str]
            Name of the Flow.

        directory_id : typing.Optional[str]
            Unique identifier for the Directory to move Flow to. Starts with `dir_`.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.move(
            id="id",
        )
        """
        response = self._raw_client.move(
            id, path=path, name=name, directory_id=directory_id, request_options=request_options
        )
        return response.data

    def list_versions(
        self,
        id: str,
        *,
        evaluator_aggregates: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListAgents:
        """
        Get a list of all the versions of a Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        evaluator_aggregates : typing.Optional[bool]
            Whether to include Evaluator aggregate results for the versions in the response

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListAgents
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.list_versions(
            id="id",
        )
        """
        response = self._raw_client.list_versions(
            id, evaluator_aggregates=evaluator_aggregates, request_options=request_options
        )
        return response.data

    def set_deployment(
        self, id: str, environment_id: str, *, version_id: str, request_options: typing.Optional[RequestOptions] = None
    ) -> AgentResponse:
        """
        Deploy Agent to an Environment.

        Set the deployed version for the specified Environment. This Agent
        will be used for calls made to the Agent in this Environment.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        environment_id : str
            Unique identifier for the Environment to deploy the Version to.

        version_id : str
            Unique identifier for the specific version of the Agent.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.set_deployment(
            id="id",
            environment_id="environment_id",
            version_id="version_id",
        )
        """
        response = self._raw_client.set_deployment(
            id, environment_id, version_id=version_id, request_options=request_options
        )
        return response.data

    def remove_deployment(
        self, id: str, environment_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Remove deployed Agent from the Environment.

        Remove the deployed version for the specified Environment. This Agent
        will no longer be used for calls made to the Agent in this Environment.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        environment_id : str
            Unique identifier for the Environment to remove the deployment from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.remove_deployment(
            id="id",
            environment_id="environment_id",
        )
        """
        response = self._raw_client.remove_deployment(id, environment_id, request_options=request_options)
        return response.data

    def list_environments(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[FileEnvironmentResponse]:
        """
        List all Environments and their deployed versions for the Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[FileEnvironmentResponse]
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.list_environments(
            id="id",
        )
        """
        response = self._raw_client.list_environments(id, request_options=request_options)
        return response.data

    def update_monitoring(
        self,
        id: str,
        *,
        activate: typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams]] = OMIT,
        deactivate: typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Activate and deactivate Evaluators for monitoring the Agent.

        An activated Evaluator will automatically be run on all new Logs
        within the Agent for monitoring purposes.

        Parameters
        ----------
        id : str

        activate : typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams]]
            Evaluators to activate for Monitoring. These will be automatically run on new Logs.

        deactivate : typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams]]
            Evaluators to deactivate. These will not be run on new Logs.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.update_monitoring(
            id="id",
        )
        """
        response = self._raw_client.update_monitoring(
            id, activate=activate, deactivate=deactivate, request_options=request_options
        )
        return response.data

    def serialize(
        self,
        id: str,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        Serialize an Agent to the .agent file format.

        Useful for storing the Agent with your code in a version control system,
        or for editing with an AI tool.

        By default, the deployed version of the Agent is returned. Use the query parameters
        `version_id` or `environment` to target a specific version of the Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        version_id : typing.Optional[str]
            A specific Version ID of the Agent to retrieve.

        environment : typing.Optional[str]
            Name of the Environment to retrieve a deployed Version from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.serialize(
            id="id",
        )
        """
        response = self._raw_client.serialize(
            id, version_id=version_id, environment=environment, request_options=request_options
        )
        return response.data

    def deserialize(self, *, agent: str, request_options: typing.Optional[RequestOptions] = None) -> AgentKernelRequest:
        """
        Deserialize an Agent from the .agent file format.

        This returns a subset of the attributes required by an Agent.
        This subset is the bit that defines the Agent version (e.g. with `model` and `temperature` etc)

        Parameters
        ----------
        agent : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentKernelRequest
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.agents.deserialize(
            agent="agent",
        )
        """
        response = self._raw_client.deserialize(agent=agent, request_options=request_options)
        return response.data


class AsyncAgentsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawAgentsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawAgentsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawAgentsClient
        """
        return self._raw_client

    async def log(
        self,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        run_id: typing.Optional[str] = OMIT,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        output_message: typing.Optional[ChatMessageParams] = OMIT,
        prompt_tokens: typing.Optional[int] = OMIT,
        reasoning_tokens: typing.Optional[int] = OMIT,
        output_tokens: typing.Optional[int] = OMIT,
        prompt_cost: typing.Optional[float] = OMIT,
        output_cost: typing.Optional[float] = OMIT,
        finish_reason: typing.Optional[str] = OMIT,
        messages: typing.Optional[typing.Sequence[ChatMessageParams]] = OMIT,
        tool_choice: typing.Optional[AgentLogRequestToolChoiceParams] = OMIT,
        agent: typing.Optional[AgentKernelRequestParams] = OMIT,
        start_time: typing.Optional[dt.datetime] = OMIT,
        end_time: typing.Optional[dt.datetime] = OMIT,
        output: typing.Optional[str] = OMIT,
        created_at: typing.Optional[dt.datetime] = OMIT,
        error: typing.Optional[str] = OMIT,
        provider_latency: typing.Optional[float] = OMIT,
        stdout: typing.Optional[str] = OMIT,
        provider_request: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        provider_response: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        log_status: typing.Optional[LogStatus] = OMIT,
        source_datapoint_id: typing.Optional[str] = OMIT,
        trace_parent_id: typing.Optional[str] = OMIT,
        user: typing.Optional[str] = OMIT,
        agent_log_request_environment: typing.Optional[str] = OMIT,
        save: typing.Optional[bool] = OMIT,
        log_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CreateAgentLogResponse:
        """
        Create an Agent Log.

        You can use query parameters `version_id`, or `environment`, to target
        an existing version of the Agent. Otherwise, the default deployed version will be chosen.

        If you create the Agent Log with a `log_status` of `incomplete`, you should later update it to `complete`
        in order to trigger Evaluators.

        Parameters
        ----------
        version_id : typing.Optional[str]
            A specific Version ID of the Agent to log to.

        environment : typing.Optional[str]
            Name of the Environment identifying a deployed version to log to.

        run_id : typing.Optional[str]
            Unique identifier for the Run to associate the Log to.

        path : typing.Optional[str]
            Path of the Agent, including the name. This locates the Agent in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Agent.

        output_message : typing.Optional[ChatMessageParams]
            The message returned by the provider.

        prompt_tokens : typing.Optional[int]
            Number of tokens in the prompt used to generate the output.

        reasoning_tokens : typing.Optional[int]
            Number of reasoning tokens used to generate the output.

        output_tokens : typing.Optional[int]
            Number of tokens in the output generated by the model.

        prompt_cost : typing.Optional[float]
            Cost in dollars associated to the tokens in the prompt.

        output_cost : typing.Optional[float]
            Cost in dollars associated to the tokens in the output.

        finish_reason : typing.Optional[str]
            Reason the generation finished.

        messages : typing.Optional[typing.Sequence[ChatMessageParams]]
            The messages passed to the to provider chat endpoint.

        tool_choice : typing.Optional[AgentLogRequestToolChoiceParams]
            Controls how the model uses tools. The following options are supported:
            - `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt.
            - `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt.
            - `'required'` means the model must call one or more of the provided tools.
            - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.

        agent : typing.Optional[AgentKernelRequestParams]
            Details of your Agent. A new Agent version will be created if the provided details are new.

        start_time : typing.Optional[dt.datetime]
            When the logged event started.

        end_time : typing.Optional[dt.datetime]
            When the logged event ended.

        output : typing.Optional[str]
            Generated output from your model for the provided inputs. Can be `None` if logging an error, or if creating a parent Log with the intention to populate it later.

        created_at : typing.Optional[dt.datetime]
            User defined timestamp for when the log was created.

        error : typing.Optional[str]
            Error message if the log is an error.

        provider_latency : typing.Optional[float]
            Duration of the logged event in seconds.

        stdout : typing.Optional[str]
            Captured log and debug statements.

        provider_request : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Raw request sent to provider.

        provider_response : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Raw response received the provider.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the prompt template.

        source : typing.Optional[str]
            Identifies where the model was called from.

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Any additional metadata to record.

        log_status : typing.Optional[LogStatus]
            Status of a Log. Set to `incomplete` if you intend to update and eventually complete the Log and want the File's monitoring Evaluators to wait until you mark it as `complete`. If log_status is not provided, observability will pick up the Log as soon as possible. Updating this from specified to unspecified is undefined behavior.

        source_datapoint_id : typing.Optional[str]
            Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.

        trace_parent_id : typing.Optional[str]
            The ID of the parent Log to nest this Log under in a Trace.

        user : typing.Optional[str]
            End-user ID related to the Log.

        agent_log_request_environment : typing.Optional[str]
            The name of the Environment the Log is associated to.

        save : typing.Optional[bool]
            Whether the request/response payloads will be stored on Humanloop.

        log_id : typing.Optional[str]
            This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CreateAgentLogResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.log()


        asyncio.run(main())
        """
        response = await self._raw_client.log(
            version_id=version_id,
            environment=environment,
            run_id=run_id,
            path=path,
            id=id,
            output_message=output_message,
            prompt_tokens=prompt_tokens,
            reasoning_tokens=reasoning_tokens,
            output_tokens=output_tokens,
            prompt_cost=prompt_cost,
            output_cost=output_cost,
            finish_reason=finish_reason,
            messages=messages,
            tool_choice=tool_choice,
            agent=agent,
            start_time=start_time,
            end_time=end_time,
            output=output,
            created_at=created_at,
            error=error,
            provider_latency=provider_latency,
            stdout=stdout,
            provider_request=provider_request,
            provider_response=provider_response,
            inputs=inputs,
            source=source,
            metadata=metadata,
            log_status=log_status,
            source_datapoint_id=source_datapoint_id,
            trace_parent_id=trace_parent_id,
            user=user,
            agent_log_request_environment=agent_log_request_environment,
            save=save,
            log_id=log_id,
            request_options=request_options,
        )
        return response.data

    async def update_log(
        self,
        id: str,
        log_id: str,
        *,
        messages: typing.Optional[typing.Sequence[ChatMessageParams]] = OMIT,
        output_message: typing.Optional[ChatMessageParams] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        output: typing.Optional[str] = OMIT,
        error: typing.Optional[str] = OMIT,
        log_status: typing.Optional[LogStatus] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> LogResponse:
        """
        Update a Log.

        Update the details of a Log with the given ID.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        log_id : str
            Unique identifier for the Log.

        messages : typing.Optional[typing.Sequence[ChatMessageParams]]
            List of chat messages that were used as an input to the Flow.

        output_message : typing.Optional[ChatMessageParams]
            The output message returned by this Flow.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the Flow Log.

        output : typing.Optional[str]
            The output of the Flow Log. Provide None to unset existing `output` value. Provide either this, `output_message` or `error`.

        error : typing.Optional[str]
            The error message of the Flow Log. Provide None to unset existing `error` value. Provide either this, `output_message` or `output`.

        log_status : typing.Optional[LogStatus]
            Status of the Flow Log. When a Flow Log is updated to `complete`, no more Logs can be added to it. Monitoring Evaluators will only run on `complete` Flow Logs.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        LogResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.update_log(
                id="id",
                log_id="log_id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.update_log(
            id,
            log_id,
            messages=messages,
            output_message=output_message,
            inputs=inputs,
            output=output,
            error=error,
            log_status=log_status,
            request_options=request_options,
        )
        return response.data

    async def call_stream(
        self,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        messages: typing.Optional[typing.Sequence[ChatMessageParams]] = OMIT,
        tool_choice: typing.Optional[AgentsCallStreamRequestToolChoiceParams] = OMIT,
        agent: typing.Optional[AgentKernelRequestParams] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        start_time: typing.Optional[dt.datetime] = OMIT,
        end_time: typing.Optional[dt.datetime] = OMIT,
        log_status: typing.Optional[LogStatus] = OMIT,
        source_datapoint_id: typing.Optional[str] = OMIT,
        trace_parent_id: typing.Optional[str] = OMIT,
        user: typing.Optional[str] = OMIT,
        agents_call_stream_request_environment: typing.Optional[str] = OMIT,
        save: typing.Optional[bool] = OMIT,
        log_id: typing.Optional[str] = OMIT,
        provider_api_keys: typing.Optional[ProviderApiKeysParams] = OMIT,
        return_inputs: typing.Optional[bool] = OMIT,
        include_trace_children: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.AsyncIterator[AgentCallStreamResponse]:
        """
        Call an Agent.

        Calling an Agent calls the model provider before logging
        the request, responses and metadata to Humanloop.

        You can use query parameters `version_id`, or `environment`, to target
        an existing version of the Agent. Otherwise the default deployed version will be chosen.

        Instead of targeting an existing version explicitly, you can instead pass in
        Agent details in the request body. In this case, we will check if the details correspond
        to an existing version of the Agent. If they do not, we will create a new version. This is helpful
        in the case where you are storing or deriving your Agent details in code.

        Parameters
        ----------
        version_id : typing.Optional[str]
            A specific Version ID of the Agent to log to.

        environment : typing.Optional[str]
            Name of the Environment identifying a deployed version to log to.

        path : typing.Optional[str]
            Path of the Agent, including the name. This locates the Agent in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Agent.

        messages : typing.Optional[typing.Sequence[ChatMessageParams]]
            The messages passed to the to provider chat endpoint.

        tool_choice : typing.Optional[AgentsCallStreamRequestToolChoiceParams]
            Controls how the model uses tools. The following options are supported:
            - `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt.
            - `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt.
            - `'required'` means the model must call one or more of the provided tools.
            - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.

        agent : typing.Optional[AgentKernelRequestParams]
            Details of your Agent. A new Agent version will be created if the provided details are new.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the prompt template.

        source : typing.Optional[str]
            Identifies where the model was called from.

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Any additional metadata to record.

        start_time : typing.Optional[dt.datetime]
            When the logged event started.

        end_time : typing.Optional[dt.datetime]
            When the logged event ended.

        log_status : typing.Optional[LogStatus]
            Status of a Log. Set to `incomplete` if you intend to update and eventually complete the Log and want the File's monitoring Evaluators to wait until you mark it as `complete`. If log_status is not provided, observability will pick up the Log as soon as possible. Updating this from specified to unspecified is undefined behavior.

        source_datapoint_id : typing.Optional[str]
            Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.

        trace_parent_id : typing.Optional[str]
            The ID of the parent Log to nest this Log under in a Trace.

        user : typing.Optional[str]
            End-user ID related to the Log.

        agents_call_stream_request_environment : typing.Optional[str]
            The name of the Environment the Log is associated to.

        save : typing.Optional[bool]
            Whether the request/response payloads will be stored on Humanloop.

        log_id : typing.Optional[str]
            This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.

        provider_api_keys : typing.Optional[ProviderApiKeysParams]
            API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization.

        return_inputs : typing.Optional[bool]
            Whether to return the inputs in the response. If false, the response will contain an empty dictionary under inputs. This is useful for reducing the size of the response. Defaults to true.

        include_trace_children : typing.Optional[bool]
            If true, populate `trace_children` for the returned Agent Log. Only applies when not streaming. Defaults to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.AsyncIterator[AgentCallStreamResponse]


        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            response = await client.agents.call_stream()
            async for chunk in response:
                yield chunk


        asyncio.run(main())
        """
        async with self._raw_client.call_stream(
            version_id=version_id,
            environment=environment,
            path=path,
            id=id,
            messages=messages,
            tool_choice=tool_choice,
            agent=agent,
            inputs=inputs,
            source=source,
            metadata=metadata,
            start_time=start_time,
            end_time=end_time,
            log_status=log_status,
            source_datapoint_id=source_datapoint_id,
            trace_parent_id=trace_parent_id,
            user=user,
            agents_call_stream_request_environment=agents_call_stream_request_environment,
            save=save,
            log_id=log_id,
            provider_api_keys=provider_api_keys,
            return_inputs=return_inputs,
            include_trace_children=include_trace_children,
            request_options=request_options,
        ) as r:
            async for data in r.data:
                yield data

    async def call(
        self,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        messages: typing.Optional[typing.Sequence[ChatMessageParams]] = OMIT,
        tool_choice: typing.Optional[AgentsCallRequestToolChoiceParams] = OMIT,
        agent: typing.Optional[AgentKernelRequestParams] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        start_time: typing.Optional[dt.datetime] = OMIT,
        end_time: typing.Optional[dt.datetime] = OMIT,
        log_status: typing.Optional[LogStatus] = OMIT,
        source_datapoint_id: typing.Optional[str] = OMIT,
        trace_parent_id: typing.Optional[str] = OMIT,
        user: typing.Optional[str] = OMIT,
        agents_call_request_environment: typing.Optional[str] = OMIT,
        save: typing.Optional[bool] = OMIT,
        log_id: typing.Optional[str] = OMIT,
        provider_api_keys: typing.Optional[ProviderApiKeysParams] = OMIT,
        return_inputs: typing.Optional[bool] = OMIT,
        include_trace_children: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentCallResponse:
        """
        Call an Agent.

        Calling an Agent calls the model provider before logging
        the request, responses and metadata to Humanloop.

        You can use query parameters `version_id`, or `environment`, to target
        an existing version of the Agent. Otherwise the default deployed version will be chosen.

        Instead of targeting an existing version explicitly, you can instead pass in
        Agent details in the request body. In this case, we will check if the details correspond
        to an existing version of the Agent. If they do not, we will create a new version. This is helpful
        in the case where you are storing or deriving your Agent details in code.

        Parameters
        ----------
        version_id : typing.Optional[str]
            A specific Version ID of the Agent to log to.

        environment : typing.Optional[str]
            Name of the Environment identifying a deployed version to log to.

        path : typing.Optional[str]
            Path of the Agent, including the name. This locates the Agent in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Agent.

        messages : typing.Optional[typing.Sequence[ChatMessageParams]]
            The messages passed to the to provider chat endpoint.

        tool_choice : typing.Optional[AgentsCallRequestToolChoiceParams]
            Controls how the model uses tools. The following options are supported:
            - `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt.
            - `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt.
            - `'required'` means the model must call one or more of the provided tools.
            - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.

        agent : typing.Optional[AgentKernelRequestParams]
            Details of your Agent. A new Agent version will be created if the provided details are new.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the prompt template.

        source : typing.Optional[str]
            Identifies where the model was called from.

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Any additional metadata to record.

        start_time : typing.Optional[dt.datetime]
            When the logged event started.

        end_time : typing.Optional[dt.datetime]
            When the logged event ended.

        log_status : typing.Optional[LogStatus]
            Status of a Log. Set to `incomplete` if you intend to update and eventually complete the Log and want the File's monitoring Evaluators to wait until you mark it as `complete`. If log_status is not provided, observability will pick up the Log as soon as possible. Updating this from specified to unspecified is undefined behavior.

        source_datapoint_id : typing.Optional[str]
            Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.

        trace_parent_id : typing.Optional[str]
            The ID of the parent Log to nest this Log under in a Trace.

        user : typing.Optional[str]
            End-user ID related to the Log.

        agents_call_request_environment : typing.Optional[str]
            The name of the Environment the Log is associated to.

        save : typing.Optional[bool]
            Whether the request/response payloads will be stored on Humanloop.

        log_id : typing.Optional[str]
            This will identify a Log. If you don't provide a Log ID, Humanloop will generate one for you.

        provider_api_keys : typing.Optional[ProviderApiKeysParams]
            API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization.

        return_inputs : typing.Optional[bool]
            Whether to return the inputs in the response. If false, the response will contain an empty dictionary under inputs. This is useful for reducing the size of the response. Defaults to true.

        include_trace_children : typing.Optional[bool]
            If true, populate `trace_children` for the returned Agent Log. Only applies when not streaming. Defaults to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentCallResponse


        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.call()


        asyncio.run(main())
        """
        response = await self._raw_client.call(
            version_id=version_id,
            environment=environment,
            path=path,
            id=id,
            messages=messages,
            tool_choice=tool_choice,
            agent=agent,
            inputs=inputs,
            source=source,
            metadata=metadata,
            start_time=start_time,
            end_time=end_time,
            log_status=log_status,
            source_datapoint_id=source_datapoint_id,
            trace_parent_id=trace_parent_id,
            user=user,
            agents_call_request_environment=agents_call_request_environment,
            save=save,
            log_id=log_id,
            provider_api_keys=provider_api_keys,
            return_inputs=return_inputs,
            include_trace_children=include_trace_children,
            request_options=request_options,
        )
        return response.data

    async def continue_stream(
        self,
        *,
        log_id: str,
        messages: typing.Sequence[ChatMessageParams],
        provider_api_keys: typing.Optional[ProviderApiKeysParams] = OMIT,
        include_trace_children: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.AsyncIterator[AgentContinueStreamResponse]:
        """
        Continue an incomplete Agent call.

        This endpoint allows continuing an existing incomplete Agent call, using the context
        from the previous interaction. The Agent will resume processing from where it left off.

        The original log must be in an incomplete state to be continued.

        The messages in the request will be appended
        to the original messages in the log.

        Parameters
        ----------
        log_id : str
            This identifies the Agent Log to continue.

        messages : typing.Sequence[ChatMessageParams]
            The additional messages with which to continue the Agent Log. Often, these should start with the Tool messages with results for the previous Assistant message's tool calls.

        provider_api_keys : typing.Optional[ProviderApiKeysParams]
            API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization.

        include_trace_children : typing.Optional[bool]
            If true, populate `trace_children` for the returned Agent Log. Defaults to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.AsyncIterator[AgentContinueStreamResponse]


        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            response = await client.agents.continue_stream(
                log_id="log_id",
                messages=[{"role": "user"}],
            )
            async for chunk in response:
                yield chunk


        asyncio.run(main())
        """
        async with self._raw_client.continue_stream(
            log_id=log_id,
            messages=messages,
            provider_api_keys=provider_api_keys,
            include_trace_children=include_trace_children,
            request_options=request_options,
        ) as r:
            async for data in r.data:
                yield data

    async def continue_(
        self,
        *,
        log_id: str,
        messages: typing.Sequence[ChatMessageParams],
        provider_api_keys: typing.Optional[ProviderApiKeysParams] = OMIT,
        include_trace_children: typing.Optional[bool] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentContinueResponse:
        """
        Continue an incomplete Agent call.

        This endpoint allows continuing an existing incomplete Agent call, using the context
        from the previous interaction. The Agent will resume processing from where it left off.

        The original log must be in an incomplete state to be continued.

        The messages in the request will be appended
        to the original messages in the log.

        Parameters
        ----------
        log_id : str
            This identifies the Agent Log to continue.

        messages : typing.Sequence[ChatMessageParams]
            The additional messages with which to continue the Agent Log. Often, these should start with the Tool messages with results for the previous Assistant message's tool calls.

        provider_api_keys : typing.Optional[ProviderApiKeysParams]
            API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization.

        include_trace_children : typing.Optional[bool]
            If true, populate `trace_children` for the returned Agent Log. Defaults to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentContinueResponse


        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.continue_(
                log_id="log_id",
                messages=[{"role": "user"}],
            )


        asyncio.run(main())
        """
        response = await self._raw_client.continue_(
            log_id=log_id,
            messages=messages,
            provider_api_keys=provider_api_keys,
            include_trace_children=include_trace_children,
            request_options=request_options,
        )
        return response.data

    async def list(
        self,
        *,
        page: typing.Optional[int] = None,
        size: typing.Optional[int] = None,
        name: typing.Optional[str] = None,
        user_filter: typing.Optional[str] = None,
        sort_by: typing.Optional[ProjectSortBy] = None,
        order: typing.Optional[SortOrder] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedDataAgentResponse:
        """
        Get a list of all Agents.

        Parameters
        ----------
        page : typing.Optional[int]
            Page number for pagination.

        size : typing.Optional[int]
            Page size for pagination. Number of Agents to fetch.

        name : typing.Optional[str]
            Case-insensitive filter for Agent name.

        user_filter : typing.Optional[str]
            Case-insensitive filter for users in the Agent. This filter matches against both email address and name of users.

        sort_by : typing.Optional[ProjectSortBy]
            Field to sort Agents by

        order : typing.Optional[SortOrder]
            Direction to sort by.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedDataAgentResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.list()


        asyncio.run(main())
        """
        response = await self._raw_client.list(
            page=page,
            size=size,
            name=name,
            user_filter=user_filter,
            sort_by=sort_by,
            order=order,
            request_options=request_options,
        )
        return response.data

    async def upsert(
        self,
        *,
        model: str,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        endpoint: typing.Optional[ModelEndpoints] = OMIT,
        template: typing.Optional[AgentRequestTemplateParams] = OMIT,
        template_language: typing.Optional[TemplateLanguage] = OMIT,
        provider: typing.Optional[ModelProviders] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        top_p: typing.Optional[float] = OMIT,
        stop: typing.Optional[AgentRequestStopParams] = OMIT,
        presence_penalty: typing.Optional[float] = OMIT,
        frequency_penalty: typing.Optional[float] = OMIT,
        other: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        seed: typing.Optional[int] = OMIT,
        response_format: typing.Optional[ResponseFormatParams] = OMIT,
        reasoning_effort: typing.Optional[AgentRequestReasoningEffortParams] = OMIT,
        tools: typing.Optional[typing.Sequence[AgentRequestToolsItemParams]] = OMIT,
        attributes: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        max_iterations: typing.Optional[int] = OMIT,
        version_name: typing.Optional[str] = OMIT,
        version_description: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        tags: typing.Optional[typing.Sequence[str]] = OMIT,
        readme: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Create an Agent or update it with a new version if it already exists.

        Agents are identified by the `ID` or their `path`. The parameters (i.e. the template, temperature, model etc.) and
        tools determine the versions of the Agent.

        You can provide `version_name` and `version_description` to identify and describe your versions.
        Version names must be unique within an Agent - attempting to create a version with a name
        that already exists will result in a 409 Conflict error.

        Parameters
        ----------
        model : str
            The model instance used, e.g. `gpt-4`. See [supported models](https://humanloop.com/docs/reference/supported-models)

        path : typing.Optional[str]
            Path of the Agent, including the name. This locates the Agent in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Agent.

        endpoint : typing.Optional[ModelEndpoints]
            The provider model endpoint used.

        template : typing.Optional[AgentRequestTemplateParams]
            The template contains the main structure and instructions for the model, including input variables for dynamic values.

            For chat models, provide the template as a ChatTemplate (a list of messages), e.g. a system message, followed by a user message with an input variable.
            For completion models, provide a prompt template as a string.

            Input variables should be specified with double curly bracket syntax: `{{input_name}}`.

        template_language : typing.Optional[TemplateLanguage]
            The template language to use for rendering the template.

        provider : typing.Optional[ModelProviders]
            The company providing the underlying model service.

        max_tokens : typing.Optional[int]
            The maximum number of tokens to generate. Provide max_tokens=-1 to dynamically calculate the maximum number of tokens to generate given the length of the prompt

        temperature : typing.Optional[float]
            What sampling temperature to use when making a generation. Higher values means the model will be more creative.

        top_p : typing.Optional[float]
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.

        stop : typing.Optional[AgentRequestStopParams]
            The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.

        presence_penalty : typing.Optional[float]
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the generation so far.

        frequency_penalty : typing.Optional[float]
            Number between -2.0 and 2.0. Positive values penalize new tokens based on how frequently they appear in the generation so far.

        other : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Other parameter values to be passed to the provider call.

        seed : typing.Optional[int]
            If specified, model will make a best effort to sample deterministically, but it is not guaranteed.

        response_format : typing.Optional[ResponseFormatParams]
            The format of the response. Only `{"type": "json_object"}` is currently supported for chat.

        reasoning_effort : typing.Optional[AgentRequestReasoningEffortParams]
            Guidance on how many reasoning tokens it should generate before creating a response to the prompt. OpenAI reasoning models (o1, o3-mini) expect a OpenAIReasoningEffort enum. Anthropic reasoning models expect an integer, which signifies the maximum token budget.

        tools : typing.Optional[typing.Sequence[AgentRequestToolsItemParams]]

        attributes : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Additional fields to describe the Prompt. Helpful to separate Prompt versions from each other with details on how they were created or used.

        max_iterations : typing.Optional[int]
            The maximum number of iterations the Agent can run. This is used to limit the number of times the Agent model is called.

        version_name : typing.Optional[str]
            Unique name for the Prompt version. Each Prompt can only have one version with a given name.

        version_description : typing.Optional[str]
            Description of the Version.

        description : typing.Optional[str]
            Description of the Prompt.

        tags : typing.Optional[typing.Sequence[str]]
            List of tags associated with this prompt.

        readme : typing.Optional[str]
            Long description of the Prompt.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.upsert(
                model="model",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.upsert(
            model=model,
            path=path,
            id=id,
            endpoint=endpoint,
            template=template,
            template_language=template_language,
            provider=provider,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            stop=stop,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty,
            other=other,
            seed=seed,
            response_format=response_format,
            reasoning_effort=reasoning_effort,
            tools=tools,
            attributes=attributes,
            max_iterations=max_iterations,
            version_name=version_name,
            version_description=version_description,
            description=description,
            tags=tags,
            readme=readme,
            request_options=request_options,
        )
        return response.data

    async def delete_agent_version(
        self, id: str, version_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Delete a version of the Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        version_id : str
            Unique identifier for the specific version of the Agent.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.delete_agent_version(
                id="id",
                version_id="version_id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.delete_agent_version(id, version_id, request_options=request_options)
        return response.data

    async def patch_agent_version(
        self,
        id: str,
        version_id: str,
        *,
        name: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Update the name or description of the Agent version.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        version_id : str
            Unique identifier for the specific version of the Agent.

        name : typing.Optional[str]
            Name of the version.

        description : typing.Optional[str]
            Description of the version.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.patch_agent_version(
                id="id",
                version_id="version_id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.patch_agent_version(
            id, version_id, name=name, description=description, request_options=request_options
        )
        return response.data

    async def get(
        self,
        id: str,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Retrieve the Agent with the given ID.

        By default, the deployed version of the Agent is returned. Use the query parameters
        `version_id` or `environment` to target a specific version of the Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        version_id : typing.Optional[str]
            A specific Version ID of the Agent to retrieve.

        environment : typing.Optional[str]
            Name of the Environment to retrieve a deployed Version from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.get(
                id="id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.get(
            id, version_id=version_id, environment=environment, request_options=request_options
        )
        return response.data

    async def delete(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete the Agent with the given ID.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.delete(
                id="id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.delete(id, request_options=request_options)
        return response.data

    async def move(
        self,
        id: str,
        *,
        path: typing.Optional[str] = OMIT,
        name: typing.Optional[str] = OMIT,
        directory_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Move the Agent to a different path or change the name.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        path : typing.Optional[str]
            Path of the Flow including the Flow name, which is used as a unique identifier.

        name : typing.Optional[str]
            Name of the Flow.

        directory_id : typing.Optional[str]
            Unique identifier for the Directory to move Flow to. Starts with `dir_`.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.move(
                id="id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.move(
            id, path=path, name=name, directory_id=directory_id, request_options=request_options
        )
        return response.data

    async def list_versions(
        self,
        id: str,
        *,
        evaluator_aggregates: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListAgents:
        """
        Get a list of all the versions of a Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        evaluator_aggregates : typing.Optional[bool]
            Whether to include Evaluator aggregate results for the versions in the response

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListAgents
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.list_versions(
                id="id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.list_versions(
            id, evaluator_aggregates=evaluator_aggregates, request_options=request_options
        )
        return response.data

    async def set_deployment(
        self, id: str, environment_id: str, *, version_id: str, request_options: typing.Optional[RequestOptions] = None
    ) -> AgentResponse:
        """
        Deploy Agent to an Environment.

        Set the deployed version for the specified Environment. This Agent
        will be used for calls made to the Agent in this Environment.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        environment_id : str
            Unique identifier for the Environment to deploy the Version to.

        version_id : str
            Unique identifier for the specific version of the Agent.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.set_deployment(
                id="id",
                environment_id="environment_id",
                version_id="version_id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.set_deployment(
            id, environment_id, version_id=version_id, request_options=request_options
        )
        return response.data

    async def remove_deployment(
        self, id: str, environment_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Remove deployed Agent from the Environment.

        Remove the deployed version for the specified Environment. This Agent
        will no longer be used for calls made to the Agent in this Environment.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        environment_id : str
            Unique identifier for the Environment to remove the deployment from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.remove_deployment(
                id="id",
                environment_id="environment_id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.remove_deployment(id, environment_id, request_options=request_options)
        return response.data

    async def list_environments(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[FileEnvironmentResponse]:
        """
        List all Environments and their deployed versions for the Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[FileEnvironmentResponse]
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.list_environments(
                id="id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.list_environments(id, request_options=request_options)
        return response.data

    async def update_monitoring(
        self,
        id: str,
        *,
        activate: typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams]] = OMIT,
        deactivate: typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AgentResponse:
        """
        Activate and deactivate Evaluators for monitoring the Agent.

        An activated Evaluator will automatically be run on all new Logs
        within the Agent for monitoring purposes.

        Parameters
        ----------
        id : str

        activate : typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams]]
            Evaluators to activate for Monitoring. These will be automatically run on new Logs.

        deactivate : typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams]]
            Evaluators to deactivate. These will not be run on new Logs.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.update_monitoring(
                id="id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.update_monitoring(
            id, activate=activate, deactivate=deactivate, request_options=request_options
        )
        return response.data

    async def serialize(
        self,
        id: str,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> None:
        """
        Serialize an Agent to the .agent file format.

        Useful for storing the Agent with your code in a version control system,
        or for editing with an AI tool.

        By default, the deployed version of the Agent is returned. Use the query parameters
        `version_id` or `environment` to target a specific version of the Agent.

        Parameters
        ----------
        id : str
            Unique identifier for Agent.

        version_id : typing.Optional[str]
            A specific Version ID of the Agent to retrieve.

        environment : typing.Optional[str]
            Name of the Environment to retrieve a deployed Version from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.serialize(
                id="id",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.serialize(
            id, version_id=version_id, environment=environment, request_options=request_options
        )
        return response.data

    async def deserialize(
        self, *, agent: str, request_options: typing.Optional[RequestOptions] = None
    ) -> AgentKernelRequest:
        """
        Deserialize an Agent from the .agent file format.

        This returns a subset of the attributes required by an Agent.
        This subset is the bit that defines the Agent version (e.g. with `model` and `temperature` etc)

        Parameters
        ----------
        agent : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AgentKernelRequest
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.agents.deserialize(
                agent="agent",
            )


        asyncio.run(main())
        """
        response = await self._raw_client.deserialize(agent=agent, request_options=request_options)
        return response.data
