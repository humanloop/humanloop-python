# This file was auto-generated by Fern from our API Definition.

from __future__ import annotations
from ..core.unchecked_base_model import UncheckedBaseModel
import pydantic
import typing
from .evaluator_response_spec import EvaluatorResponseSpec
from .environment_response import EnvironmentResponse
import datetime as dt
from .user_response import UserResponse
from .version_status import VersionStatus
from .input_response import InputResponse
from .evaluator_aggregate import EvaluatorAggregate
from ..core.pydantic_utilities import IS_PYDANTIC_V2
from ..core.pydantic_utilities import update_forward_refs


class EvaluatorResponse(UncheckedBaseModel):
    """
    Version of the Evaluator used to provide judgments.
    """

    path: str = pydantic.Field()
    """
    Path of the Evaluator including the Evaluator name, which is used as a unique identifier.
    """

    id: str = pydantic.Field()
    """
    Unique identifier for the Evaluator.
    """

    directory_id: typing.Optional[str] = pydantic.Field(default=None)
    """
    ID of the directory that the file is in on Humanloop.
    """

    commit_message: typing.Optional[str] = pydantic.Field(default=None)
    """
    Message describing the changes made.
    """

    spec: EvaluatorResponseSpec
    name: str = pydantic.Field()
    """
    Name of the Evaluator, which is used as a unique identifier.
    """

    version_id: str = pydantic.Field()
    """
    Unique identifier for the specific Evaluator Version. If no query params provided, the default deployed Evaluator Version is returned.
    """

    type: typing.Optional[typing.Literal["evaluator"]] = None
    environments: typing.Optional[typing.List[EnvironmentResponse]] = pydantic.Field(default=None)
    """
    The list of environments the Evaluator Version is deployed to.
    """

    created_at: dt.datetime
    updated_at: dt.datetime
    created_by: typing.Optional[UserResponse] = pydantic.Field(default=None)
    """
    The user who created the Evaluator.
    """

    status: VersionStatus
    last_used_at: dt.datetime
    version_logs_count: int = pydantic.Field()
    """
    The number of logs that have been generated for this Evaluator Version
    """

    total_logs_count: int = pydantic.Field()
    """
    The number of logs that have been generated across all Evaluator Versions
    """

    inputs: typing.List[InputResponse] = pydantic.Field()
    """
    Inputs associated to the Evaluator. Inputs correspond to any of the variables used within the Evaluator template.
    """

    evaluators: typing.Optional[typing.List["MonitoringEvaluatorResponse"]] = pydantic.Field(default=None)
    """
    Evaluators that have been attached to this Evaluator that are used for monitoring logs.
    """

    evaluator_aggregates: typing.Optional[typing.List[EvaluatorAggregate]] = pydantic.Field(default=None)
    """
    Aggregation of Evaluator results for the Evaluator Version.
    """

    attributes: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = pydantic.Field(default=None)
    """
    Additional fields to describe the Evaluator. Helpful to separate Evaluator versions from each other with details on how they were created or used.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


from .flow_response import FlowResponse  # noqa: E402
from .monitoring_evaluator_response import MonitoringEvaluatorResponse  # noqa: E402
from .prompt_response import PromptResponse  # noqa: E402
from .tool_response import ToolResponse  # noqa: E402
from .version_deployment_response import VersionDeploymentResponse  # noqa: E402
from .version_id_response import VersionIdResponse  # noqa: E402

update_forward_refs(FlowResponse, EvaluatorResponse=EvaluatorResponse)
update_forward_refs(MonitoringEvaluatorResponse, EvaluatorResponse=EvaluatorResponse)
update_forward_refs(PromptResponse, EvaluatorResponse=EvaluatorResponse)
update_forward_refs(ToolResponse, EvaluatorResponse=EvaluatorResponse)
update_forward_refs(VersionDeploymentResponse, EvaluatorResponse=EvaluatorResponse)
update_forward_refs(VersionIdResponse, EvaluatorResponse=EvaluatorResponse)
update_forward_refs(EvaluatorResponse)
