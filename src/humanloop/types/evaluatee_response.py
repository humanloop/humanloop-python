# This file was auto-generated by Fern from our API Definition.

from __future__ import annotations
from ..core.unchecked_base_model import UncheckedBaseModel
from .evaluator_response import EvaluatorResponse
from .flow_response import FlowResponse
from .monitoring_evaluator_response import MonitoringEvaluatorResponse
from .prompt_response import PromptResponse
from .tool_response import ToolResponse
from .version_deployment_response import VersionDeploymentResponse
from .version_id_response import VersionIdResponse
from .evaluated_version_response import EvaluatedVersionResponse
import typing
import pydantic
import datetime as dt
from ..core.pydantic_utilities import IS_PYDANTIC_V2
from ..core.pydantic_utilities import update_forward_refs


class EvaluateeResponse(UncheckedBaseModel):
    """
    Version of the Evaluatee being evaluated.
    """

    version: EvaluatedVersionResponse
    batch_id: typing.Optional[str] = pydantic.Field(default=None)
    """
    Unique identifier for the batch of Logs to include in the Evaluation Report.
    """

    orchestrated: bool = pydantic.Field()
    """
    Whether the Prompt/Tool is orchestrated by Humanloop. Default is `True`. If `False`, a log for the Prompt/Tool should be submitted by the user via the API.
    """

    pinned: bool = pydantic.Field()
    """
    Pinned Evaluatees are shown in Humanloop's Overview, allowing you to use them as baselines for comparison.
    """

    added_at: typing.Optional[dt.datetime] = pydantic.Field(default=None)
    """
    When the Evaluatee was added to the Evaluation.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


update_forward_refs(EvaluatorResponse, EvaluateeResponse=EvaluateeResponse)
update_forward_refs(FlowResponse, EvaluateeResponse=EvaluateeResponse)
update_forward_refs(MonitoringEvaluatorResponse, EvaluateeResponse=EvaluateeResponse)
update_forward_refs(PromptResponse, EvaluateeResponse=EvaluateeResponse)
update_forward_refs(ToolResponse, EvaluateeResponse=EvaluateeResponse)
update_forward_refs(VersionDeploymentResponse, EvaluateeResponse=EvaluateeResponse)
update_forward_refs(VersionIdResponse, EvaluateeResponse=EvaluateeResponse)
