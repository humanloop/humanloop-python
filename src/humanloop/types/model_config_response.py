# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic

from ..core.pydantic_utilities import IS_PYDANTIC_V2
from ..core.unchecked_base_model import UncheckedBaseModel
from .chat_message_with_tool_call import ChatMessageWithToolCall
from .config_tool_response import ConfigToolResponse
from .model_config_response_stop import ModelConfigResponseStop
from .model_endpoints import ModelEndpoints
from .model_providers import ModelProviders
from .response_format import ResponseFormat
from .tool_config_response import ToolConfigResponse


class ModelConfigResponse(UncheckedBaseModel):
    """
    Model config request.

    Contains fields that are common to all (i.e. both chat and complete) endpoints.
    """

    id: str = pydantic.Field()
    """
    String ID of config. Starts with `config_`.
    """

    other: typing.Optional[typing.Dict[str, typing.Any]] = pydantic.Field(default=None)
    """
    Other parameter values to be passed to the provider call.
    """

    type: typing.Literal["model"] = "model"
    name: typing.Optional[str] = pydantic.Field(default=None)
    """
    A friendly display name for the model config. If not provided, a name will be generated.
    """

    description: typing.Optional[str] = pydantic.Field(default=None)
    """
    A description of the model config.
    """

    provider: typing.Optional[ModelProviders] = pydantic.Field(default=None)
    """
    The company providing the underlying model service.
    """

    model: str = pydantic.Field()
    """
    The model instance used. E.g. text-davinci-002.
    """

    max_tokens: typing.Optional[int] = pydantic.Field(default=None)
    """
    The maximum number of tokens to generate. Provide max_tokens=-1 to dynamically calculate the maximum number of tokens to generate given the length of the prompt
    """

    temperature: typing.Optional[float] = pydantic.Field(default=None)
    """
    What sampling temperature to use when making a generation. Higher values means the model will be more creative.
    """

    top_p: typing.Optional[float] = pydantic.Field(default=None)
    """
    An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.
    """

    stop: typing.Optional[ModelConfigResponseStop] = pydantic.Field(default=None)
    """
    The string (or list of strings) after which the model will stop generating. The returned text will not contain the stop sequence.
    """

    presence_penalty: typing.Optional[float] = pydantic.Field(default=None)
    """
    Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the generation so far.
    """

    frequency_penalty: typing.Optional[float] = pydantic.Field(default=None)
    """
    Number between -2.0 and 2.0. Positive values penalize new tokens based on how frequently they appear in the generation so far.
    """

    seed: typing.Optional[int] = pydantic.Field(default=None)
    """
    If specified, model will make a best effort to sample deterministically, but it is not guaranteed.
    """

    response_format: typing.Optional[ResponseFormat] = pydantic.Field(default=None)
    """
    The format of the response. Only type json_object is currently supported for chat.
    """

    prompt_template: typing.Optional[str] = pydantic.Field(default=None)
    """
    Prompt template that will take your specified inputs to form your final request to the model. NB: Input variables within the prompt template should be specified with syntax: {{INPUT_NAME}}.
    """

    chat_template: typing.Optional[typing.List[ChatMessageWithToolCall]] = pydantic.Field(default=None)
    """
    Messages prepended to the list of messages sent to the provider. These messages that will take your specified inputs to form your final request to the provider model. NB: Input variables within the template should be specified with syntax: {{INPUT_NAME}}.
    """

    tool_configs: typing.Optional[typing.List[ToolConfigResponse]] = pydantic.Field(default=None)
    """
    NB: Deprecated with tools field. Definition of tools shown to the model.
    """

    tools: typing.Optional[typing.List[ConfigToolResponse]] = pydantic.Field(default=None)
    """
    Tools shown to the model.
    """

    endpoint: typing.Optional[ModelEndpoints] = pydantic.Field(default=None)
    """
    The provider model endpoint used.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
