# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
import datetime as dt
from .requests.create_evaluator_log_request_judgment import CreateEvaluatorLogRequestJudgmentParams
from .requests.create_evaluator_log_request_spec import CreateEvaluatorLogRequestSpecParams
from ..core.request_options import RequestOptions
from ..types.create_evaluator_log_response import CreateEvaluatorLogResponse
from ..core.serialization import convert_and_respect_annotation_metadata
from ..core.unchecked_base_model import construct_type
from ..errors.unprocessable_entity_error import UnprocessableEntityError
from ..types.http_validation_error import HttpValidationError
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from ..types.project_sort_by import ProjectSortBy
from ..types.sort_order import SortOrder
from ..core.pagination import SyncPager
from ..types.evaluator_response import EvaluatorResponse
from ..types.paginated_data_evaluator_response import PaginatedDataEvaluatorResponse
from .requests.src_external_app_models_v_5_evaluators_evaluator_request_spec import (
    SrcExternalAppModelsV5EvaluatorsEvaluatorRequestSpecParams,
)
from ..core.jsonable_encoder import jsonable_encoder
from ..types.version_status import VersionStatus
from ..types.list_evaluators import ListEvaluators
from ..types.file_environment_response import FileEnvironmentResponse
from ..requests.evaluator_activation_deactivation_request_activate_item import (
    EvaluatorActivationDeactivationRequestActivateItemParams,
)
from ..requests.evaluator_activation_deactivation_request_deactivate_item import (
    EvaluatorActivationDeactivationRequestDeactivateItemParams,
)
from ..core.client_wrapper import AsyncClientWrapper
from ..core.pagination import AsyncPager

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class EvaluatorsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def log(
        self,
        *,
        parent_id: str,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        start_time: typing.Optional[dt.datetime] = OMIT,
        end_time: typing.Optional[dt.datetime] = OMIT,
        output: typing.Optional[str] = OMIT,
        created_at: typing.Optional[dt.datetime] = OMIT,
        error: typing.Optional[str] = OMIT,
        provider_latency: typing.Optional[float] = OMIT,
        stdout: typing.Optional[str] = OMIT,
        provider_request: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        provider_response: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source_datapoint_id: typing.Optional[str] = OMIT,
        trace_parent_id: typing.Optional[str] = OMIT,
        batch_id: typing.Optional[str] = OMIT,
        user: typing.Optional[str] = OMIT,
        create_evaluator_log_request_environment: typing.Optional[str] = OMIT,
        save: typing.Optional[bool] = OMIT,
        judgment: typing.Optional[CreateEvaluatorLogRequestJudgmentParams] = OMIT,
        spec: typing.Optional[CreateEvaluatorLogRequestSpecParams] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CreateEvaluatorLogResponse:
        """
        Submit Evaluator judgment for an existing Log.

        Creates a new Log. The evaluated Log will be set as the parent of the created Log.

        Parameters
        ----------
        parent_id : str
            Identifier of the evaluated Log. The newly created Log will have this one set as parent.

        version_id : typing.Optional[str]
            ID of the Evaluator version to log against.

        environment : typing.Optional[str]
            Name of the Environment identifying a deployed version to log to.

        path : typing.Optional[str]
            Path of the Evaluator, including the name. This locates the Evaluator in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Evaluator.

        start_time : typing.Optional[dt.datetime]
            When the logged event started.

        end_time : typing.Optional[dt.datetime]
            When the logged event ended.

        output : typing.Optional[str]
            Generated output from the LLM. Only populated for LLM Evaluator Logs.

        created_at : typing.Optional[dt.datetime]
            User defined timestamp for when the log was created.

        error : typing.Optional[str]
            Error message if the log is an error.

        provider_latency : typing.Optional[float]
            Duration of the logged event in seconds.

        stdout : typing.Optional[str]
            Captured log and debug statements.

        provider_request : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Raw request sent to provider. Only populated for LLM Evaluator Logs.

        provider_response : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Raw response received the provider. Only populated for LLM Evaluator Logs.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the prompt template.

        source : typing.Optional[str]
            Identifies where the model was called from.

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Any additional metadata to record.

        source_datapoint_id : typing.Optional[str]
            Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.

        trace_parent_id : typing.Optional[str]
            The ID of the parent Log to nest this Log under in a Trace.

        batch_id : typing.Optional[str]
            Unique identifier for the Batch to add this Batch to. Batches are used to group Logs together for Evaluations. A Batch will be created if one with the given ID does not exist.

        user : typing.Optional[str]
            End-user ID related to the Log.

        create_evaluator_log_request_environment : typing.Optional[str]
            The name of the Environment the Log is associated to.

        save : typing.Optional[bool]
            Whether the request/response payloads will be stored on Humanloop.

        judgment : typing.Optional[CreateEvaluatorLogRequestJudgmentParams]
            Evaluator assessment of the Log.

        spec : typing.Optional[CreateEvaluatorLogRequestSpecParams]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CreateEvaluatorLogResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.log(
            parent_id="parent_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "evaluators/log",
            method="POST",
            params={
                "version_id": version_id,
                "environment": environment,
            },
            json={
                "path": path,
                "id": id,
                "start_time": start_time,
                "end_time": end_time,
                "output": output,
                "created_at": created_at,
                "error": error,
                "provider_latency": provider_latency,
                "stdout": stdout,
                "provider_request": provider_request,
                "provider_response": provider_response,
                "inputs": inputs,
                "source": source,
                "metadata": metadata,
                "parent_id": parent_id,
                "source_datapoint_id": source_datapoint_id,
                "trace_parent_id": trace_parent_id,
                "batch_id": batch_id,
                "user": user,
                "environment": create_evaluator_log_request_environment,
                "save": save,
                "judgment": convert_and_respect_annotation_metadata(
                    object_=judgment, annotation=CreateEvaluatorLogRequestJudgmentParams, direction="write"
                ),
                "spec": convert_and_respect_annotation_metadata(
                    object_=spec, annotation=CreateEvaluatorLogRequestSpecParams, direction="write"
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    CreateEvaluatorLogResponse,
                    construct_type(
                        type_=CreateEvaluatorLogResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list(
        self,
        *,
        page: typing.Optional[int] = None,
        size: typing.Optional[int] = None,
        name: typing.Optional[str] = None,
        user_filter: typing.Optional[str] = None,
        sort_by: typing.Optional[ProjectSortBy] = None,
        order: typing.Optional[SortOrder] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SyncPager[EvaluatorResponse]:
        """
        Get a list of all Evaluators.

        Parameters
        ----------
        page : typing.Optional[int]
            Page offset for pagination.

        size : typing.Optional[int]
            Page size for pagination. Number of Evaluators to fetch.

        name : typing.Optional[str]
            Case-insensitive filter for Evaluator name.

        user_filter : typing.Optional[str]
            Case-insensitive filter for users in the Evaluator. This filter matches against both email address and name of users.

        sort_by : typing.Optional[ProjectSortBy]
            Field to sort Evaluators by

        order : typing.Optional[SortOrder]
            Direction to sort by.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SyncPager[EvaluatorResponse]
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        response = client.evaluators.list(
            size=1,
        )
        for item in response:
            yield item
        # alternatively, you can paginate page-by-page
        for page in response.iter_pages():
            yield page
        """
        page = page if page is not None else 1
        _response = self._client_wrapper.httpx_client.request(
            "evaluators",
            method="GET",
            params={
                "page": page,
                "size": size,
                "name": name,
                "user_filter": user_filter,
                "sort_by": sort_by,
                "order": order,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _parsed_response = typing.cast(
                    PaginatedDataEvaluatorResponse,
                    construct_type(
                        type_=PaginatedDataEvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                _has_next = True
                _get_next = lambda: self.list(
                    page=page + 1,
                    size=size,
                    name=name,
                    user_filter=user_filter,
                    sort_by=sort_by,
                    order=order,
                    request_options=request_options,
                )
                _items = _parsed_response.records
                return SyncPager(has_next=_has_next, items=_items, get_next=_get_next)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upsert(
        self,
        *,
        spec: SrcExternalAppModelsV5EvaluatorsEvaluatorRequestSpecParams,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        commit_message: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluatorResponse:
        """
        Create an Evaluator or update it with a new version if it already exists.

        Evaluators are identified by the `ID` or their `path`. The spec provided determines the version of the Evaluator.

        If you provide a commit message, then the new version will be committed;
        otherwise it will be uncommitted. If you try to commit an already committed version,
        an exception will be raised.

        Parameters
        ----------
        spec : SrcExternalAppModelsV5EvaluatorsEvaluatorRequestSpecParams

        path : typing.Optional[str]
            Path of the Evaluator, including the name. This locates the Evaluator in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Evaluator.

        commit_message : typing.Optional[str]
            Message describing the changes made.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.upsert(
            path="Shared Evaluators/Accuracy Evaluator",
            spec={
                "arguments_type": "target_required",
                "return_type": "number",
                "evaluator_type": "python",
                "code": "def evaluate(answer, target):\n    return 0.5",
            },
            commit_message="Initial commit",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "evaluators",
            method="POST",
            json={
                "path": path,
                "id": id,
                "commit_message": commit_message,
                "spec": convert_and_respect_annotation_metadata(
                    object_=spec,
                    annotation=SrcExternalAppModelsV5EvaluatorsEvaluatorRequestSpecParams,
                    direction="write",
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(
        self,
        id: str,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluatorResponse:
        """
        Retrieve the Evaluator with the given ID.

        By default, the deployed version of the Evaluator is returned. Use the query parameters
        `version_id` or `environment` to target a specific version of the Evaluator.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        version_id : typing.Optional[str]
            A specific Version ID of the Evaluator to retrieve.

        environment : typing.Optional[str]
            Name of the Environment to retrieve a deployed Version from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.get(
            id="ev_890bcd",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}",
            method="GET",
            params={
                "version_id": version_id,
                "environment": environment,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete the Evaluator with the given ID.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.delete(
            id="ev_890bcd",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def move(
        self,
        id: str,
        *,
        path: typing.Optional[str] = OMIT,
        name: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluatorResponse:
        """
        Move the Evaluator to a different path or change the name.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        path : typing.Optional[str]
            Path of the Evaluator including the Evaluator name, which is used as a unique identifier.

        name : typing.Optional[str]
            Name of the Evaluator, which is used as a unique identifier.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.move(
            id="ev_890bcd",
            path="new directory/new name",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "path": path,
                "name": name,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_versions(
        self,
        id: str,
        *,
        status: typing.Optional[VersionStatus] = None,
        evaluator_aggregates: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListEvaluators:
        """
        Get a list of all the versions of an Evaluator.

        Parameters
        ----------
        id : str
            Unique identifier for the Evaluator.

        status : typing.Optional[VersionStatus]
            Filter versions by status: 'uncommitted', 'committed'. If no status is provided, all versions are returned.

        evaluator_aggregates : typing.Optional[bool]
            Whether to include Evaluator aggregate results for the versions in the response

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListEvaluators
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.list_versions(
            id="ev_890bcd",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/versions",
            method="GET",
            params={
                "status": status,
                "evaluator_aggregates": evaluator_aggregates,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ListEvaluators,
                    construct_type(
                        type_=ListEvaluators,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def commit(
        self, id: str, version_id: str, *, commit_message: str, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluatorResponse:
        """
        Commit a version of the Evaluator with a commit message.

        If the version is already committed, an exception will be raised.

        Parameters
        ----------
        id : str
            Unique identifier for Prompt.

        version_id : str
            Unique identifier for the specific version of the Evaluator.

        commit_message : str
            Message describing the changes made.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.commit(
            id="ev_890bcd",
            version_id="evv_012def",
            commit_message="Initial commit",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/versions/{jsonable_encoder(version_id)}/commit",
            method="POST",
            json={
                "commit_message": commit_message,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def set_deployment(
        self, id: str, environment_id: str, *, version_id: str, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluatorResponse:
        """
        Deploy Evaluator to an Environment.

        Set the deployed version for the specified Environment. This Evaluator
        will be used for calls made to the Evaluator in this Environment.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        environment_id : str
            Unique identifier for the Environment to deploy the Version to.

        version_id : str
            Unique identifier for the specific version of the Evaluator.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.set_deployment(
            id="ev_890bcd",
            environment_id="staging",
            version_id="evv_012def",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/environments/{jsonable_encoder(environment_id)}",
            method="POST",
            params={
                "version_id": version_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def remove_deployment(
        self, id: str, environment_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Remove deployed Evaluator from the Environment.

        Remove the deployed version for the specified Environment. This Evaluator
        will no longer be used for calls made to the Evaluator in this Environment.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        environment_id : str
            Unique identifier for the Environment to remove the deployment from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.remove_deployment(
            id="ev_890bcd",
            environment_id="staging",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/environments/{jsonable_encoder(environment_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_environments(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[FileEnvironmentResponse]:
        """
        List all Environments and their deployed versions for the Evaluator.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[FileEnvironmentResponse]
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.list_environments(
            id="ev_890bcd",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/environments",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.List[FileEnvironmentResponse],
                    construct_type(
                        type_=typing.List[FileEnvironmentResponse],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_monitoring(
        self,
        id: str,
        *,
        activate: typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams]] = OMIT,
        deactivate: typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluatorResponse:
        """
        Activate and deactivate Evaluators for monitoring the Evaluator.

        An activated Evaluator will automatically be run on all new Logs
        within the Evaluator for monitoring purposes.

        Parameters
        ----------
        id : str

        activate : typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams]]
            Evaluators to activate for Monitoring. These will be automatically run on new Logs.

        deactivate : typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams]]
            Evaluators to deactivate. These will not be run on new Logs.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        from humanloop import Humanloop

        client = Humanloop(
            api_key="YOUR_API_KEY",
        )
        client.evaluators.update_monitoring(
            id="id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/evaluators",
            method="POST",
            json={
                "activate": convert_and_respect_annotation_metadata(
                    object_=activate,
                    annotation=typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams],
                    direction="write",
                ),
                "deactivate": convert_and_respect_annotation_metadata(
                    object_=deactivate,
                    annotation=typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams],
                    direction="write",
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncEvaluatorsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def log(
        self,
        *,
        parent_id: str,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        start_time: typing.Optional[dt.datetime] = OMIT,
        end_time: typing.Optional[dt.datetime] = OMIT,
        output: typing.Optional[str] = OMIT,
        created_at: typing.Optional[dt.datetime] = OMIT,
        error: typing.Optional[str] = OMIT,
        provider_latency: typing.Optional[float] = OMIT,
        stdout: typing.Optional[str] = OMIT,
        provider_request: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        provider_response: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        inputs: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source: typing.Optional[str] = OMIT,
        metadata: typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]] = OMIT,
        source_datapoint_id: typing.Optional[str] = OMIT,
        trace_parent_id: typing.Optional[str] = OMIT,
        batch_id: typing.Optional[str] = OMIT,
        user: typing.Optional[str] = OMIT,
        create_evaluator_log_request_environment: typing.Optional[str] = OMIT,
        save: typing.Optional[bool] = OMIT,
        judgment: typing.Optional[CreateEvaluatorLogRequestJudgmentParams] = OMIT,
        spec: typing.Optional[CreateEvaluatorLogRequestSpecParams] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CreateEvaluatorLogResponse:
        """
        Submit Evaluator judgment for an existing Log.

        Creates a new Log. The evaluated Log will be set as the parent of the created Log.

        Parameters
        ----------
        parent_id : str
            Identifier of the evaluated Log. The newly created Log will have this one set as parent.

        version_id : typing.Optional[str]
            ID of the Evaluator version to log against.

        environment : typing.Optional[str]
            Name of the Environment identifying a deployed version to log to.

        path : typing.Optional[str]
            Path of the Evaluator, including the name. This locates the Evaluator in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Evaluator.

        start_time : typing.Optional[dt.datetime]
            When the logged event started.

        end_time : typing.Optional[dt.datetime]
            When the logged event ended.

        output : typing.Optional[str]
            Generated output from the LLM. Only populated for LLM Evaluator Logs.

        created_at : typing.Optional[dt.datetime]
            User defined timestamp for when the log was created.

        error : typing.Optional[str]
            Error message if the log is an error.

        provider_latency : typing.Optional[float]
            Duration of the logged event in seconds.

        stdout : typing.Optional[str]
            Captured log and debug statements.

        provider_request : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Raw request sent to provider. Only populated for LLM Evaluator Logs.

        provider_response : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Raw response received the provider. Only populated for LLM Evaluator Logs.

        inputs : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            The inputs passed to the prompt template.

        source : typing.Optional[str]
            Identifies where the model was called from.

        metadata : typing.Optional[typing.Dict[str, typing.Optional[typing.Any]]]
            Any additional metadata to record.

        source_datapoint_id : typing.Optional[str]
            Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair.

        trace_parent_id : typing.Optional[str]
            The ID of the parent Log to nest this Log under in a Trace.

        batch_id : typing.Optional[str]
            Unique identifier for the Batch to add this Batch to. Batches are used to group Logs together for Evaluations. A Batch will be created if one with the given ID does not exist.

        user : typing.Optional[str]
            End-user ID related to the Log.

        create_evaluator_log_request_environment : typing.Optional[str]
            The name of the Environment the Log is associated to.

        save : typing.Optional[bool]
            Whether the request/response payloads will be stored on Humanloop.

        judgment : typing.Optional[CreateEvaluatorLogRequestJudgmentParams]
            Evaluator assessment of the Log.

        spec : typing.Optional[CreateEvaluatorLogRequestSpecParams]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CreateEvaluatorLogResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.log(
                parent_id="parent_id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "evaluators/log",
            method="POST",
            params={
                "version_id": version_id,
                "environment": environment,
            },
            json={
                "path": path,
                "id": id,
                "start_time": start_time,
                "end_time": end_time,
                "output": output,
                "created_at": created_at,
                "error": error,
                "provider_latency": provider_latency,
                "stdout": stdout,
                "provider_request": provider_request,
                "provider_response": provider_response,
                "inputs": inputs,
                "source": source,
                "metadata": metadata,
                "parent_id": parent_id,
                "source_datapoint_id": source_datapoint_id,
                "trace_parent_id": trace_parent_id,
                "batch_id": batch_id,
                "user": user,
                "environment": create_evaluator_log_request_environment,
                "save": save,
                "judgment": convert_and_respect_annotation_metadata(
                    object_=judgment, annotation=CreateEvaluatorLogRequestJudgmentParams, direction="write"
                ),
                "spec": convert_and_respect_annotation_metadata(
                    object_=spec, annotation=CreateEvaluatorLogRequestSpecParams, direction="write"
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    CreateEvaluatorLogResponse,
                    construct_type(
                        type_=CreateEvaluatorLogResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list(
        self,
        *,
        page: typing.Optional[int] = None,
        size: typing.Optional[int] = None,
        name: typing.Optional[str] = None,
        user_filter: typing.Optional[str] = None,
        sort_by: typing.Optional[ProjectSortBy] = None,
        order: typing.Optional[SortOrder] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncPager[EvaluatorResponse]:
        """
        Get a list of all Evaluators.

        Parameters
        ----------
        page : typing.Optional[int]
            Page offset for pagination.

        size : typing.Optional[int]
            Page size for pagination. Number of Evaluators to fetch.

        name : typing.Optional[str]
            Case-insensitive filter for Evaluator name.

        user_filter : typing.Optional[str]
            Case-insensitive filter for users in the Evaluator. This filter matches against both email address and name of users.

        sort_by : typing.Optional[ProjectSortBy]
            Field to sort Evaluators by

        order : typing.Optional[SortOrder]
            Direction to sort by.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncPager[EvaluatorResponse]
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            response = await client.evaluators.list(
                size=1,
            )
            async for item in response:
                yield item
            # alternatively, you can paginate page-by-page
            async for page in response.iter_pages():
                yield page


        asyncio.run(main())
        """
        page = page if page is not None else 1
        _response = await self._client_wrapper.httpx_client.request(
            "evaluators",
            method="GET",
            params={
                "page": page,
                "size": size,
                "name": name,
                "user_filter": user_filter,
                "sort_by": sort_by,
                "order": order,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _parsed_response = typing.cast(
                    PaginatedDataEvaluatorResponse,
                    construct_type(
                        type_=PaginatedDataEvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                _has_next = True
                _get_next = lambda: self.list(
                    page=page + 1,
                    size=size,
                    name=name,
                    user_filter=user_filter,
                    sort_by=sort_by,
                    order=order,
                    request_options=request_options,
                )
                _items = _parsed_response.records
                return AsyncPager(has_next=_has_next, items=_items, get_next=_get_next)
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upsert(
        self,
        *,
        spec: SrcExternalAppModelsV5EvaluatorsEvaluatorRequestSpecParams,
        path: typing.Optional[str] = OMIT,
        id: typing.Optional[str] = OMIT,
        commit_message: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluatorResponse:
        """
        Create an Evaluator or update it with a new version if it already exists.

        Evaluators are identified by the `ID` or their `path`. The spec provided determines the version of the Evaluator.

        If you provide a commit message, then the new version will be committed;
        otherwise it will be uncommitted. If you try to commit an already committed version,
        an exception will be raised.

        Parameters
        ----------
        spec : SrcExternalAppModelsV5EvaluatorsEvaluatorRequestSpecParams

        path : typing.Optional[str]
            Path of the Evaluator, including the name. This locates the Evaluator in the Humanloop filesystem and is used as as a unique identifier. For example: `folder/name` or just `name`.

        id : typing.Optional[str]
            ID for an existing Evaluator.

        commit_message : typing.Optional[str]
            Message describing the changes made.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.upsert(
                path="Shared Evaluators/Accuracy Evaluator",
                spec={
                    "arguments_type": "target_required",
                    "return_type": "number",
                    "evaluator_type": "python",
                    "code": "def evaluate(answer, target):\n    return 0.5",
                },
                commit_message="Initial commit",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "evaluators",
            method="POST",
            json={
                "path": path,
                "id": id,
                "commit_message": commit_message,
                "spec": convert_and_respect_annotation_metadata(
                    object_=spec,
                    annotation=SrcExternalAppModelsV5EvaluatorsEvaluatorRequestSpecParams,
                    direction="write",
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(
        self,
        id: str,
        *,
        version_id: typing.Optional[str] = None,
        environment: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluatorResponse:
        """
        Retrieve the Evaluator with the given ID.

        By default, the deployed version of the Evaluator is returned. Use the query parameters
        `version_id` or `environment` to target a specific version of the Evaluator.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        version_id : typing.Optional[str]
            A specific Version ID of the Evaluator to retrieve.

        environment : typing.Optional[str]
            Name of the Environment to retrieve a deployed Version from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.get(
                id="ev_890bcd",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}",
            method="GET",
            params={
                "version_id": version_id,
                "environment": environment,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Delete the Evaluator with the given ID.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.delete(
                id="ev_890bcd",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def move(
        self,
        id: str,
        *,
        path: typing.Optional[str] = OMIT,
        name: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluatorResponse:
        """
        Move the Evaluator to a different path or change the name.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        path : typing.Optional[str]
            Path of the Evaluator including the Evaluator name, which is used as a unique identifier.

        name : typing.Optional[str]
            Name of the Evaluator, which is used as a unique identifier.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.move(
                id="ev_890bcd",
                path="new directory/new name",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "path": path,
                "name": name,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_versions(
        self,
        id: str,
        *,
        status: typing.Optional[VersionStatus] = None,
        evaluator_aggregates: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ListEvaluators:
        """
        Get a list of all the versions of an Evaluator.

        Parameters
        ----------
        id : str
            Unique identifier for the Evaluator.

        status : typing.Optional[VersionStatus]
            Filter versions by status: 'uncommitted', 'committed'. If no status is provided, all versions are returned.

        evaluator_aggregates : typing.Optional[bool]
            Whether to include Evaluator aggregate results for the versions in the response

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ListEvaluators
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.list_versions(
                id="ev_890bcd",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/versions",
            method="GET",
            params={
                "status": status,
                "evaluator_aggregates": evaluator_aggregates,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ListEvaluators,
                    construct_type(
                        type_=ListEvaluators,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def commit(
        self, id: str, version_id: str, *, commit_message: str, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluatorResponse:
        """
        Commit a version of the Evaluator with a commit message.

        If the version is already committed, an exception will be raised.

        Parameters
        ----------
        id : str
            Unique identifier for Prompt.

        version_id : str
            Unique identifier for the specific version of the Evaluator.

        commit_message : str
            Message describing the changes made.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.commit(
                id="ev_890bcd",
                version_id="evv_012def",
                commit_message="Initial commit",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/versions/{jsonable_encoder(version_id)}/commit",
            method="POST",
            json={
                "commit_message": commit_message,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def set_deployment(
        self, id: str, environment_id: str, *, version_id: str, request_options: typing.Optional[RequestOptions] = None
    ) -> EvaluatorResponse:
        """
        Deploy Evaluator to an Environment.

        Set the deployed version for the specified Environment. This Evaluator
        will be used for calls made to the Evaluator in this Environment.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        environment_id : str
            Unique identifier for the Environment to deploy the Version to.

        version_id : str
            Unique identifier for the specific version of the Evaluator.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.set_deployment(
                id="ev_890bcd",
                environment_id="staging",
                version_id="evv_012def",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/environments/{jsonable_encoder(environment_id)}",
            method="POST",
            params={
                "version_id": version_id,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def remove_deployment(
        self, id: str, environment_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Remove deployed Evaluator from the Environment.

        Remove the deployed version for the specified Environment. This Evaluator
        will no longer be used for calls made to the Evaluator in this Environment.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        environment_id : str
            Unique identifier for the Environment to remove the deployment from.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.remove_deployment(
                id="ev_890bcd",
                environment_id="staging",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/environments/{jsonable_encoder(environment_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_environments(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[FileEnvironmentResponse]:
        """
        List all Environments and their deployed versions for the Evaluator.

        Parameters
        ----------
        id : str
            Unique identifier for Evaluator.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[FileEnvironmentResponse]
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.list_environments(
                id="ev_890bcd",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/environments",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    typing.List[FileEnvironmentResponse],
                    construct_type(
                        type_=typing.List[FileEnvironmentResponse],  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_monitoring(
        self,
        id: str,
        *,
        activate: typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams]] = OMIT,
        deactivate: typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EvaluatorResponse:
        """
        Activate and deactivate Evaluators for monitoring the Evaluator.

        An activated Evaluator will automatically be run on all new Logs
        within the Evaluator for monitoring purposes.

        Parameters
        ----------
        id : str

        activate : typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams]]
            Evaluators to activate for Monitoring. These will be automatically run on new Logs.

        deactivate : typing.Optional[typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams]]
            Evaluators to deactivate. These will not be run on new Logs.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EvaluatorResponse
            Successful Response

        Examples
        --------
        import asyncio

        from humanloop import AsyncHumanloop

        client = AsyncHumanloop(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.evaluators.update_monitoring(
                id="id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"evaluators/{jsonable_encoder(id)}/evaluators",
            method="POST",
            json={
                "activate": convert_and_respect_annotation_metadata(
                    object_=activate,
                    annotation=typing.Sequence[EvaluatorActivationDeactivationRequestActivateItemParams],
                    direction="write",
                ),
                "deactivate": convert_and_respect_annotation_metadata(
                    object_=deactivate,
                    annotation=typing.Sequence[EvaluatorActivationDeactivationRequestDeactivateItemParams],
                    direction="write",
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EvaluatorResponse,
                    construct_type(
                        type_=EvaluatorResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(
                        HttpValidationError,
                        construct_type(
                            type_=HttpValidationError,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
